\chapter{a Dependent Type System}
\label{chapter:Surface}
\thispagestyle{myheadings}

\section{Introduction}

Despite the usability issues this thesis hopes to correct, dependent type systems are still one of the most promising technologies for correct programming.
Since proofs are programs, there is no additional syntax for programmers to learn.
The proof system is predictable from the perspective of a functional programmer. 
\todo{awk sentence}

The \textbf{surface type system}\todo{is there a better name then surface lang?} presented in this chapter provides a minimal dependent type system.
The rules of the type system are intended to be as simple as possible and compatible with other well studied intentional dependent type theories.
It has several (but not all) of the standard properties of dependent type theory.
As much as possible, the syntax uses standard modern notation\footnote{
  Several alternative syntaxes exist in the literature.
  In this document the typed polymorphic identity function is written, $\lambda-\,x\Rightarrow x\ :\,\left(X:\star\right)\rightarrow X\rightarrow X$.
  In \cite{10.1016/0890-5401(88)90005-3} it might be written $\left(\lambda X:\star\right)\left(\lambda x:X\right)x\ :\,\left[X:\star\right]\left[x:X\right]X$.
  In \cite{HoTTbook} it might be written $\lambda X.\lambda x.x\ :\,\underset{\left(X:\mathcal{U}\right)}{\prod}X\rightarrow X$.}\todo{Martin Loff/Hoff (TODO pr notation)}.

The surface type system will serve both as foundation for later chapters and a self contained technical introduction to dependent types.
Even when useing the full system described in later chapters, programmers will only need to think about the surface system.
By design, the machinery that deals with equality addressed in later chapters will be invisible to programers.
Everything presented in later chapters is designed to reinforce an understanding of the surface type system, and make it easier to use.

% overview, What
The surface language deviates from a standard dependent type theory to include features for programming at the expense of logical correctness.
Specifically the language allows general recursion, since general recursion is useful for programmers.
\Tit{} is also supported since it simplifies the system, and makes the meta-theory slightly easier.
Despite this, type soundness is achievable, and a practical type checking system is given.

Though similar systems have been studied over the last few decades this chapter aims to give a self contained presentation, along with examples.
The surface language has been a good platform to conduct research into full spectrum dependent type theory, and hopefully this exposition will be a helpful introduction for other researchers.

\section{Surface Language Syntax}

% What syntax
The syntax for the surface language is in \Fref{surface-pre-syntax}.
The syntax supports: variables, type annotations, a single type universe, dependent function types, recursive dependent functions, and function applications.
Type annotations are written with two colons to differentiate it from the formal typing judgments that will appear more frequently in this text.
In the implemented language a user of the programming language would use a single colon.

There is no distinction between types and terms in the syntax\footnote{
  terms and types are usually separated, except in the syntax of full-spectrum dependent type systems where separating them would require many redundant rules.
  }, both are referred to as expressions.
However, capital metavariables are used in positions that are intended as types, and lowercase metavariables are used when an expression is intended to be a term.
For instance, in annotation syntax where $m::M$ means $m$ can be a term and $M$ should be a type.
% Metavariables that intend to quantify equivalent terms will be noted with primes or subscripts, 
% Metavariables that type other metavairbles will often use the same letter

\todo{more about f being recursive?}
\todo{extrinsic}

\begin{figure}
% \begin{grammar}{x,y,z,f}{variable identifier}
% \end{grammar}
% \begin{grammar}{\Gamma\Coloneqq}{type context}
%   \mathbf{\lozenge}                        & empty context \\
%   \mathbf{Gamma,x:M}                       & extend context with x of type M \\
% \end{grammar}

\begin{tabular}{lcll}
\multicolumn{4}{l}{variable identifiers,}\tabularnewline
\multicolumn{4}{l}{$x,y,z,f$}\tabularnewline
\multicolumn{4}{l}{expressions,}\tabularnewline
$m,n,M,N$ & $\Coloneqq$ & $x$ & variable\tabularnewline
  & $|$ & $m::M$ & annotation\tabularnewline
  & $|$ & $\star$ & type universe\tabularnewline
  & $|$ & $\left(x:M\right)\rightarrow N$ & function type\tabularnewline
  & $|$ & $\mathsf{fun}\,f\,x\Rightarrow m$ & function\tabularnewline
  & $|$ & $m\,n$ & application\tabularnewline
\multicolumn{4}{l}{type contexts,}\tabularnewline
$\Gamma$ & $\Coloneqq$ & $\lozenge$ $|$ $\Gamma,x:M$ & \tabularnewline
\end{tabular}\caption{Surface Language Syntax}
\label{fig:surface-pre-syntax}
\end{figure}
  
Several standard abbreviations are listed in \Fref{surface-pre-syntax-abrev}.
\begin{figure}
\begin{tabular}{lclll}
$\left(x:M\right)\rightarrow N$ & written & $M\rightarrow N$ & when  & $x\notin fv\left(N\right)$\tabularnewline
$\mathsf{fun}\,f\,x\Rightarrow m$ & written & $\lambda x\Rightarrow m$ & when  & $f\notin fv\left(m\right)$\tabularnewline
$...\,x\Rightarrow\lambda y\Rightarrow m$ & written & $...\,x\,y\Rightarrow m$ &  & \tabularnewline
$x$ & written & $-$ & when  & $x\notin fv\left(m\right)$ when $x$ binds $m$\tabularnewline
\end{tabular}
  
where $fv$ is a function that returns the set of free variables in an expression
\caption{Surface Language Abbreviations}
\label{fig:surface-pre-syntax-abrev}
\end{figure}

\section{Examples}

The surface system is extremely expressive.
Several example surface language constructions can be found in \Fref{surface-examples}.
Turnstile notion is abused slightly so that examples can be indexed by other expressions that obey type rules.
For instance, we can say $refl_{2_{c}:\mathbb{N}_{c}}\ :\ 2_{c}\doteq_{\mathbb{N}_{c}}2_{c}$ since $\mathbb{N}_{c}:\star$ and $2_{c}:\mathbb{N}_{c}$.

\begin{sidewaysfigure}
\begin{tabular}{lllll}
  & $\vdash\perp_{c}$ & $\coloneqq\left(X:\star\right)\rightarrow X$ & $:\star$ & \makecell[l]{Void, ``empty'' type,\\ logical false}\tabularnewline
  & $\vdash Unit_{c}$ & $\coloneqq\left(X:\star\right)\rightarrow X\rightarrow X$ & $:\star$ & Unit, logical true\tabularnewline
  & $\vdash tt_{c}$ & $\coloneqq\lambda-\,x\Rightarrow x$ & $:Unit_{c}$ & \makecell[l]{trivial proposition,\\ polymorphic identity}\tabularnewline
  & $\vdash\mathbb{B}_{c}$ & $\coloneqq\left(X:\star\right)\rightarrow X\rightarrow X\rightarrow X$ & $:\star$ & booleans\tabularnewline
  & $\vdash true_{c}$ & $\coloneqq\lambda-\,then\,-\Rightarrow then$ & $:\mathbb{B}_{c}$ & boolean true\tabularnewline
  & $\vdash false_{c}$ & $\coloneqq\lambda-\,-\,else\Rightarrow else$ & $:\mathbb{B}_{c}$ & boolean false\tabularnewline
$x:\mathbb{B}_{c}$ & $\vdash!_{c}x$ & $\coloneqq x\,\mathbb{B}_{c}\,false_{c}\,true_{c}$ & $:\mathbb{B}_{c}$ & boolean not\tabularnewline
$x:\mathbb{B}_{c},y:\mathbb{B}_{c}$ & $\vdash x\,\&_{c}\,y$ & $\coloneqq x\,\mathbb{B}_{c}\,y\,false_{c}$ & $:\mathbb{B}_{c}$ & boolean and\tabularnewline
  & $\vdash\mathbb{N}_{c}$ & $\coloneqq\left(X:\star\right)\rightarrow(X\rightarrow X)\rightarrow X\rightarrow X$ & $:\star$ & natural numbers\tabularnewline
  & $\vdash0_{c}$ & $\coloneqq\lambda-\,-\,z\Rightarrow z$ & $:\mathbb{N}_{c}$ & \tabularnewline
  & $\vdash1_{c}$ & $\coloneqq\lambda-\,s\,z\Rightarrow s\,z$ & $:\mathbb{N}_{c}$ & \tabularnewline
  & $\vdash2_{c}$ & $\coloneqq\lambda-\,s\,z\Rightarrow s\left(s\,z\right)$ & $:\mathbb{N}_{c}$ & \tabularnewline
  & $\vdash n_{c}$ & $\coloneqq\lambda-\,s\,z\Rightarrow s^{n}\,z$ & $:\mathbb{N}_{c}$ & \tabularnewline
$x:\mathbb{N}_{c},y:\mathbb{N}_{c}$ & $\vdash x+_{c}y$ & $\coloneqq\lambda X\,s\,z\Rightarrow x\,X\,s\,\left(y\,X\,s\,z\right)$ & $:\mathbb{N}_{c}$ & \tabularnewline
$X:\star,Y:\star$ & $\vdash X\times_{c}Y$ & $\coloneqq\left(Z:\star\right)\rightarrow(X\rightarrow Y\rightarrow Z)\rightarrow Z$ & $:\star$ & pair, logical and\tabularnewline
$X:\star,Y:\star$ & $\vdash Either_{c}\,X\,Y$ & $\coloneqq\left(Z:\star\right)\rightarrow(X\rightarrow Z)\rightarrow(Y\rightarrow Z)\rightarrow Z$ & $:\star$ & either, logical or\tabularnewline
$X:\star$ & $\vdash\lnot_{c}X$ & $\coloneqq X\rightarrow\perp_{c}$ & $:\star$ & logical negation\tabularnewline
$x:\mathbb{N}_{c}$ & $\vdash Even_{c}\,x$ & $\coloneqq\mathbb{N}_{c}\,\star\,\left(\lambda x\Rightarrow\lnot_{c}x\right)\,Unit_{c}$ & $:\star$ & $x$ is an even number\tabularnewline
$X:\star,Y:X\rightarrow\star$ & $\vdash\exists_{c}x:X\Rightarrow Y\,x$ & $\coloneqq\left(C:\star\right)\rightarrow\left((x:X)\rightarrow Y\,x\rightarrow C\right)\rightarrow C$ & $:\star$ & \makecell[l]{dependent pair,\\ logical exists}\tabularnewline
$X:\star,x_{1}:X,x_{2}:X$ & $\vdash x_{1}\doteq_{X}x_{2}$ & $\coloneqq\left(C:\left(X\rightarrow\star\right)\right)\rightarrow C\,x_{1}\rightarrow C\,x_{2}$ & $:\star$ & Leibniz equality\tabularnewline
$X:\star,x:X$ & $\vdash refl_{x:X}$ & $\coloneqq\lambda-\,cx\Rightarrow cx$ & $:x\doteq_{X}x$ & reflexivity\tabularnewline
% $X:\star,x_{1}:X,x_{2}:X$ & $\vdash sym_{x_{1},x_{2}:X}$ & $\coloneqq\lambda p\,C\Rightarrow p\left(\lambda x\Rightarrow C\,x\rightarrow C\,x_{1}\right)\,\left(\lambda x\Rightarrow x\right)$ & $:x_{1}\doteq_{X}x_{2}\rightarrow x_{2}\doteq_{X}x_{1}$ & symmetry\tabularnewline
\end{tabular}

\todo[inline]{use tagged union notation}
\todo[inline]{break out eq for a better table}
\todo[inline]{suc, pred as an example of an unpleasant encoding, also citation}
\todo[inline]{trans, cong}
\todo[inline]{list, vec, singleton}\caption{Example Surface Language Expressions}
\label{fig:surface-examples}
\end{sidewaysfigure}

\subsection{Church encodings}

Data types are expressible using Church encodings, (in the style of System F).
Church encodings embed the elimination principle of a data type into higher order functions.
For instance, boolean data is eliminated against true and false, two tags with no additional data.
This can also be recognized as the familiar if-then-else construct. \todo{awk}
So $\mathbb{B}_{c}$ encodes the possibility of choice between two elements, $true_{c}$ picks the $then$ branch, and $false_{c}$ picks the $else$ branch.

Natural numbers\footnote{called \textbf{church numerals} in this scheme.} are encodable with two tags, zero and successor.
Where the successor tag also contains the result of the preceding number.
So $\mathbb{N}_{c}$ encodes those two choices, $(X\rightarrow X)$ handles the recursive result of the prior number in the successor case, and the $X$ argument specifies how to handle the base case of $0$.
This can be viewed as a simple looping construct with temporary storage.

Parameterized data types such as pairs and the $Either$ type can also be encoded in this scheme.
A pair type can be used in any way the two terms it contains can, so a pair is defined as the curried input to a function.
The $Either$ type is handled if both possibilities are handled, so it is defined as a higher order function that will return an output if both possibilities are handled for input.

\todo{church encoding citation?}

% not necessarily convenient
Church encodings provide a theoretically lightweight way of working with data in a minimal lambda calculus.
However, they are inconvenient.
For instance, the predecessor function on natural numbers is not as simple as its behavior would imply.
To make the system easier for programmers, data types will be added directly in Chapter 4.

\subsection{Proposition encodings}

In general we associate the truth value of a proposition with the inhabitation of a type by a meaningful value.
This meaningful inhabitant corresponds to a proof.
So, $\perp_{c}$, the ``empty'' type, can be interpreted as a false proposition.
While $Unit_{c}$ can be interpreted as a trivially true proposition, since it has only one good inhabitant.

Several of the church encoded data types we have seen can also be interpreted as logical predicates.
For instance, the tuple type can be interpreted as logical $and$.
$X\times_{c}Y$ can be inhabited when both $X$ and $Y$ are inhabited.
The $Either$ type can be interpreted as logical $or$.
$Either_{c}\,X\,Y$ can be inhabited when either $X$ or $Y$ is inhabited.

With dependent types, more interesting logical predicates can be encoded.
For instance, we can characterize when a number is even with $Even_{c}\,x$.
We can show that $2$ is even by showing that $Even_{c}\,2_{c}$ is inhabited with the term $\lambda s\Rightarrow s\,tt_{c}$.

Other predicates are encodable in the style of Calculus of Constructions\cite{10.1016/0890-5401(88)90005-3}.
For instance, we can encode the existential as $\exists_{c}$ as shown in \Fref{surface-examples}.
Then if we want to show $\exists_{c}x:\mathbb{N}_{c}\Rightarrow\,Even_{c}\,x$ we need to find a suitable inhabitant of that type.
$0$ is clearly an even number, so our inhabitant could be $\lambda f\Rightarrow f\,0_{c}\,tt_{c}$.
Note that the existential is equivalent to the tuple if $Y$ does not depend on the value of $X$.

One of the most interesting propositions is the proposition of equality.
$\doteq$ is referred to as \textbf{Leibniz equality} since two terms are equal when they behave the same on all predicates\footnote{
  The identification of indiscernibles is called \textbf{Leibniz law} in philosophy.
  Leibniz assumed a metaphysical notion of identification of ``substance''s, not a mathematical notion of equality.
  See Section 9 \cite{Leibniz1686}.}\todo{cite the ency of philosophy}.
We can prove $\doteq$ is an equivalence within the system by proving it is reflexive, symmetric, and transitive.
\todo{give example}
% Additionally we can prove congruence.
\todo[inline]{talk more about congruence}
\todo[inline]{footnote on Leibniz equality for alt encoding}

\subsection{Large Eliminations}

\todo[inline]{double check large elimination def.
consistent with the notes % https://github.com/RobertHarper/hott-notes/blob/5339576f55a4b7f5d04734370a5117491c44b1fe/notes_week5.tex#L155 .
would like better explanation}

It is useful for a type to depend specifically on term level data, this is called \textbf{large elimination}.
Large elimination can be simulated with \tit{}.

\begin{tabular}{llll}
  $toLogic$ & $\coloneqq\lambda b\Rightarrow b\,\star\,Unit_{c}\,\perp_{c}$ & $:$ & $\mathbb{B}_{c}\rightarrow\star$\tabularnewline
  $isPos$ & $\coloneqq\lambda n\Rightarrow n\,\star\,(\lambda-\Rightarrow Unit_{c})\,\perp_{c}$ & $:$ & $\mathbb{N}_{c}\rightarrow\star$\tabularnewline
\end{tabular}
  
For instance, $toLogic$ can convert a $\mathbb{B}_{c}$ term into its corresponding logical type, $toLogic\ true_{c}\,\equiv\, Unit_{c}$ while $toLogic\ false_{c}\, \equiv\, \perp_{c}$.
The expression $isPos$ has similar behavior, going to $\perp_{c}$ at $0_{c}$ and $Unit_{c}$ otherwise.

Note that such functions are not possible in the Calculus of Constructions.

\subsection{Inequalities}

Large eliminations can be used to prove inequalities that can be hard or impossible to express in other minimal dependent type theories such as the Calculus of Constructions.
For instance,

\begin{tabular}{lcll}
  $\lambda pr\Rightarrow pr\,\left(\lambda x\Rightarrow x\right)\,\perp_{c}$ & : & $\lnot_{c}\star\doteq_{\star}\perp_{c}$ & \makecell{the type universe is distinct\\ from Logical False}\tabularnewline
  $\lambda pr\Rightarrow pr\,\left(\lambda x\Rightarrow x\right)\,tt_{c}$ & : & $\lnot_{c}Unit_{c}\doteq_{\star}\perp_{c}$ &  \makecell{Logical True is distinct\\ from Logical False}\tabularnewline
  $\lambda pr\Rightarrow pr\,toLogic\,tt_{c}$ & : & $\lnot true_{c}\doteq_{\mathbb{B}_{c}}false_{c}$ &  \makecell{boolean true and false\\ are distinct}\tabularnewline
  $\lambda pr\Rightarrow pr\,isPos\,tt_{c}$ & : & $\lnot1_{c}\doteq_{\mathbb{N}_{c}}0_{c}$ & 1 and 0 are distinct\tabularnewline
  \end{tabular}
  
\todo[inline]{1st not sensible in CC}

\todo[inline]{2 possibly in CC?}

Note that a proof of $\lnot1_{c}\doteq_{\mathbb{N}_{c}}0_{c}$ is not possible in the Calculus of Constructions\cite{10.2307/2274575}\footnote{
  Martin Hofmann excellently motivates the reasoning in the exercises of \cite{hofmann_1997}}.
\todo[inline]{citation is actually for an MLTT, but if good enough for Hoff good enough for me}

\subsection{Recursion}

Additionally, the syntax of functions build in unrestricted recursion.
Though not always necessary, recursion can be very helpful for writing programs.
For instance, here is (an inefficient) function that calculates Fibonacci numbers.

$\mathsf{fun}\,f\,x\Rightarrow case_{c}\,x\,0_{c}\left(\lambda px\Rightarrow case_{c}\,px\,1_{c}\left(\lambda-\Rightarrow f\left(x-_{c}1\right)+_{c}f\left(x-_{c}2\right)\right)\right)$

Assuming appropriate definitions for $case_{c}$, and subtraction.

Recursion can also be used to simulate induction. 
We won't see much of recursion until Chapter 4, when data types are introduced and larger examples are easier to express.
\todo[inline]{GCD, recursive types?}

\section{Surface Language Type Assignment System}

When is an expression reasonable? The expression $\star\star\star\star$ is allowed by the grammar of the language, but seems dubious.
%Since $\star$  is not a function,  it has no way of being given an input by application.
Type systems can disallow bad terms like these which in turn prevents bad runtime behavior.

We will present our type system as a \textbf{type assignment system} (\ac{TAS}).
Type assignment systems are convineint to study the theory of a dependently typed language, becuase they do not require type annotations. %and will be easier to work with than other styles of typing that require variables to be annotated.
% For instance, $\mathsf{fun}\,f\,x\Rightarrow m$ does not require a type be given for $f$ or $a$.
\todo{church/curry?}
Practically this means that the type assignment system may need to infer an unrealistic amount of information if used as a type checking algorithm.
This also means that terms do not necessarily have unique typings.
For instance $\tasys\lambda x\Rightarrow x:\mathbb{N}_{c}\rightarrow\mathbb{N}_{c}$, and $\tasys\lambda x\Rightarrow x:\mathbb{B}_{c}\rightarrow\mathbb{B}_{c}$.
These issues will be addressed when the more practical, \bidir{} type system is introduced. 
\todo{move negative stuff later?}

\begin{figure}
\[
\frac{x:M\in\Gamma}{\Gamma\tasys x\,:\,M}\,\rulename{ty-var}
\]

\[
\frac{\Gamma\tasys m\,:\,M}{\Gamma\tasys m::M\,:\,M}\,\rulename{ty-::}
\]

\[
\frac{{\color{gray}\ }}{\Gamma\tasys\star\,:\,\star}\,\rulename{ty-\star}
\]

\[
\frac{\Gamma\tasys M\,:\,\star\quad\Gamma,x:M\tasys N\,:\,\star}{\Gamma\tasys\left(x:M\right)\rightarrow N\,:\,\star}\,\rulename{ty-\mathsf{fun}-ty}
\]

\[
\frac{\Gamma\tasys m\,:\,\left(x:N\right)\rightarrow M\quad\Gamma\tasys n\,:\,N}{\Gamma\tasys m\,n\,:\,M\left[x\coloneqq n\right]}\,\rulename{ty-\mathsf{fun}-app}
\]

\[
\frac{\Gamma,f:\left(x:N\right)\rightarrow M,x:N\tasys m\,:\,M}{\Gamma\tasys\mathsf{fun}\,f\,x\Rightarrow m\,:\,\left(x:N\right)\rightarrow M}\,\rulename{ty-\mathsf{fun}}
\]

\[
\frac{\Gamma\tasys m\,:\,M\quad M\equiv M'}{\Gamma\tasys m\,:\,M'}\,\rulename{ty-conv}
\]

\caption{Surface Language Type Assignment System}
\label{fig:surface-TAS}
\end{figure}

The rules of the type assignment system are listed in \Fref{surface-TAS}.
Variables get their type from the typing contextb by the \rulename{ty-var} rule.
Type annotations reflect a correct typing derivation in the \rulename{ty-::} rule.
\Tit{} is recognized by the \rulename{ty-\star} rule.
The \rulename{ty-\mathsf{fun}-ty} rule forms dependent function types.
The \rulename{ty-\mathsf{fun}-app} rule shows how to type function application, by substituting the argument term directly into the dependent function type.
Functions are typed with a variable for recursive reference along with a variable for the argument in \rulename{ty-\mathsf{fun}}.
Finally, \rulename{ty-conv} alows type derivations to be \textbf{converted} to an equivelent type.

% meta-theory type soundness From the programming language perspective
The most important property of a type system is \textbf{type soundness}\footnote{also called \textbf{type safety}}.
Type soundness is often motivated with the slogan, ``well typed programs don't get stuck''\cite{MILNER1978348}\footnote{in Milner's original paper, he used ``wrong'' instead of ``stuck''}.
Given the syntax of the surface language, there is potential for a program to ``get stuck'' when an argument is applied to a non-function constructor.
For example, $\star\ 1_{c}$ would be stuck since $\star$ is not a function, so it cannot compute when given the argument $1_{c}$.
A good type system will make such unreasonable programs impossible.

Type soundness can be shown with a \textbf{progress} and \textbf{preservation}\footnote{also called \textbf{Subject Reduction}} style proof\footnote{
  The first proof published in this style is \cite{WRIGHT199438} though their progress lemma is a bit different from modern presentations.
  Most relevant textbooks outline forms of this proof for non-dependent type systems.
  For instance, Part 2 of \cite{pierce2002types}, \cite{KOKKE2020102440}, Chapter 11 of \cite{chlipala2017formal}.
  % Chapter 3 of \cite{sjoberg2015dependently} has a similar progress and preservation style proof for a dependently typed language.
  }.
\todo{cite parts of things in latex?}
\todo{TAPL cites Harper as a co-originator of progress-preservation.
 Maybe just email him?  it might be also good to get him for intractability (blum stuff).
 might want to review his book first}
The preservation lemma shows that typing information is invariant over evaluation.
While the progress lemma shows that a single step of evaluation for a well typed term in an empty context will not ``get stuck''.
By iterating these lemmas together, it is possible to show that the type system prevents a term from evaluating to the class of bad behavior described above.
For a progress and preservation style proof of a dependently typed language, everything hinges on a suitable definition of the $\equiv$ relation.

The $\equiv$ relation characterizes when terms are ``obviously'' or ``automatically'' equal.
Because the $\equiv$ relation is usually based on the definition of computation, rather then on extrinsic properties, it is called \textbf{definitional equality}\todo{is that actually why?}\footnote{also called \textbf{Judgmental Equality}, since it is defined via judgments}.
Usually it is desirable to make the definitional equality relation as large as possible, since the programmer in the system will get more equalities ``for free''.
This chapter will opt for an easier (but less powerful) $\equiv$ relation, since Chapter 3 will give an alternative way to avoid definitional equalities during type checking.

In a progress and preservation style proof, the $\equiv$ relation should 

\begin{itemize}
\item be reflexive, $m\equiv m$ 
\item be symmetric, if $m\equiv m'$ then $m'\equiv m$ 
\item be transitive, if $m\equiv m'$ and $m'\equiv m''$ then $m\equiv m''$ 
\item be closed under substitutions and evaluation, for instance if $m\equiv m'$ and $n\equiv n'$ then $m\left[x\coloneqq n\right]\equiv m'\left[x\coloneqq n'\right]$ 
\item distinguish between type constructors, for instance $\star\cancel{\equiv}\left(x:N\right)\rightarrow M$ 
\end{itemize}
A particularly simple definition of $\equiv$ arises by equating any terms that share a reduct via a system of parallel reductions

\[
\frac{m\Rrightarrow_{\ast}\,n\quad m'\Rrightarrow_{\ast}\,n}{m\equiv m'}\,\rulename{\equiv-Def}
\]

this relation 
\begin{itemize}
\item is reflexive, by definition
\item is symmetric, automatically
\item is transitive, if $\Rrightarrow_{\ast}$ is confluent
\item is closed under substitution if $\Rrightarrow_{\ast}$ is closed under
substitution, closed under evaluation automatically
\item distinguishes type constructors, if they are stable under reduction.
For instance,
\begin{itemize}
\item if $\forall NM.\left(x:N\right)\rightarrow M\Rrightarrow P$ implies $P=\left(x:N'\right)\rightarrow M'$
\item and $\star\Rrightarrow P$ implies $P=\star$
\item then $\left(x:N\right)\rightarrow M\cancel{\equiv}\star$
\end{itemize}
\end{itemize}
\begin{figure}
\[
\frac{m\Rrightarrow m'\quad n\Rrightarrow n'}{\left(\mathsf{fun}\,f\,x\Rightarrow m\right)n\Rrightarrow m'\left[f\coloneqq\mathsf{fun}\,f\,x\Rightarrow m',x\coloneqq n'\right]}\,\rulename{\Rrightarrow-\mathsf{fun}-app-red}
\]
\[
\frac{m\Rrightarrow m'}{m::M\Rrightarrow m'}\,\rulename{\Rrightarrow-::-red}
\]

\[
\frac{\,}{x\Rrightarrow x}\,\rulename{\Rrightarrow-var}
\]
\[
\frac{m\Rrightarrow m'\quad M\Rrightarrow M'}{m::M\Rrightarrow m'::M'}\,\rulename{\Rrightarrow-::}
\]

\[
\frac{\,}{\star\Rrightarrow\star}\,\rulename{\Rrightarrow-}\star
\]

\[
\frac{M\Rrightarrow M'\quad N\Rrightarrow N'}{\left(x:M\right)\rightarrow N\Rrightarrow\left(x:M'\right)\rightarrow N'}\,\rulename{\Rrightarrow-\mathsf{fun}-ty}
\]

\[
\frac{m\Rrightarrow m'}{\mathsf{fun}\,f\,x\Rightarrow m\,\Rrightarrow\,\mathsf{fun}\,f\,x\Rightarrow m'}\,\rulename{\Rrightarrow-\mathsf{fun}}
\]

\[
\frac{m\Rrightarrow m'\quad n\Rrightarrow n'}{m\,n\Rrightarrow m'\,n'}\,\rulename{\Rrightarrow-\mathsf{fun}-app}
\]

\[
\frac{\,}{m\Rrightarrow_{\ast}m}\,\rulename{\Rrightarrow_{\ast}-refl}
\]
\[
\frac{m\Rrightarrow_{\ast}m'\quad m'\Rrightarrow m''}{m\Rrightarrow_{\ast}m''}\,\rulename{\Rrightarrow_{\ast}-trans}
\]

\caption{Surface Language Parallel Reductions}
\label{fig:surface-reduction}
\end{figure}
  
Parallel reductions are defined to make confluence easy to prove, by allowing the simultaneous evaluation of any available reduction.
The system of parallel reductions is defined in \Fref{surface-reduction}.
The only interesting rules are \rulename{\Rrightarrow-\mathsf{fun}-app-red} and \rulename{\Rrightarrow-::-red} since they directly preform reductions.
The \rulename{\Rrightarrow-\mathsf{fun}-app-red} rule recursively reduces a function given an argument.
The \rulename{\Rrightarrow-::-red} rule removes a type annotation, making type annotations definitionally irrelevant.
The other rules are entirely structural.
Repeating parallel reductions zero or more times is written $\Rrightarrow_{\ast}$.

While this is a sufficient presentation of definitional equality, other variants of the relation are possible.
For instance it is possible to extend the relation with contextual information, type information, explicit proofs of equality (as in Extensional Type Theory), uncomputable relations (as in \cite{jia2010dependent}).
It is also common to assume the properties of $\equiv$ hold without proof.

Some lemmas need to quantify over simultaneous substitutions.
These simultaneous substitutions will be quantified with the variables $\sigma$, $\tau$.
For instance, if $\sigma(x) = \star$ and $\sigma(y) = 1_c$, then instead of writing $(x\ y)[x \coloneqq \star,y \coloneqq 1_c]\ =\ (\star\ 1_c)$ we would write $(x\ y)[\sigma]\ =\ (\star\ 1_c)$.

\todo{what properties are needed over substitutions?}

\subsection{Definitional Equality}

We now have enough information to prove the critical properties of definitional equality.
\todo{index theorem by chapter}\todo{would like to combine these?}

\subsubsection{Reflexivity Lemmas}
\begin{lem}
$\Rrightarrow$ is reflexive.

The following rule is admissible,

\[
\frac{\,}{m\Rrightarrow\,m}\,\rulename{\Rrightarrow-refl}
\]
\end{lem}

\begin{proof}
by induction on the syntax of $m$
\end{proof}
\begin{fact}
$\Rrightarrow_{\ast}$ is reflexive.
\end{fact}

\begin{lem}
$\equiv$ is reflexive.

The following rule is admissible,
\[
\frac{\,}{m\equiv m}\,\rulename{\equiv-refl}
\]
\end{lem}

\begin{proof}
since $\Rrightarrow_{\ast}$ is reflexive
\end{proof}

\subsubsection{Closure Lemmas}
\begin{lem}
$\Rrightarrow$ is closed under substitutions.

The following rule is admissible for every substitution $\sigma$
\[
\frac{m\Rrightarrow m'}{m\left[\sigma\right]\Rrightarrow m'\left[\sigma\right]}\,\rulename{\Rrightarrow-sub-\sigma}
\]
\end{lem}


\todo{is this lemma needed or is it just to accommodate stupid binding stuff
in coq?}
\begin{proof}
by induction on the $\Rrightarrow$ relation, using \rulename{\Rrightarrow-refl}
in the \rulename{\Rrightarrow-var} case.
\end{proof}
\begin{lem}
$\Rrightarrow$ is closed under substitutions that step.

Where $\sigma$, $\tau$ is a substitution.
Where $\sigma\Rrightarrow\tau$ means for every $x$, $\sigma\left(x\right)\Rrightarrow\tau\left(x\right)$.
\todo{awk}
The following rule is admissible
\[
\frac{m\Rrightarrow m'\quad\sigma\Rrightarrow\tau}{m\left[\sigma\right]\Rrightarrow m'\left[\tau\right]}\,\rulename{\Rrightarrow-sub}
\]
\end{lem}
\begin{proof}
by induction on the $\Rrightarrow$ relation.
\end{proof}

\begin{lem}
$\Rrightarrow_{\ast}$ is closed under substitutions that step.
\[
\frac{m\Rrightarrow_{\ast}m'\quad\sigma\Rrightarrow\tau}{m\left[\sigma\right]\Rrightarrow_{\ast}\,m'\left[\tau\right]}\,\rulename{\Rrightarrow_{\ast}-sub}
\]
is admissible 
\end{lem}

\begin{proof}
by induction on the $\Rrightarrow_{\ast}$ relation. 
\end{proof}
\begin{lem}
$\equiv$ is closed under substitutions that step.
\[
\frac{m\equiv m'\quad\sigma\Rrightarrow\tau}{m\left[\sigma\right]\equiv m'\left[\tau\right]}\,\rulename{\equiv-sub}
\]
is admissible.
\end{lem}

\begin{cor}
$\equiv$ is closed under substituted reduction.
\end{cor}

\[
\frac{n\Rrightarrow_{\ast}n'}{m\left[x\coloneqq n\right]\equiv m\left[x\coloneqq n'\right]}
\]

\begin{proof}
By repeated $\rulename{\Rrightarrow_{\ast}-sub}$ and $\equiv\rulename{-Def}$
\end{proof}

\subsubsection{Transitivity}

To prove the transitivity of the $\equiv$, we will first need to prove that \textbf{$\Rrightarrow_{\ast}$ }is \textbf{confluent}.
A relation $R$ is confluent\footnote{also called \textbf{Church-Rosser}} when, for all $m$, $n$, $n'$, if $mRn$ and $\:mRn'$ then exists exists $n''$ such that $nRn''$. % and $n'Rn''$.
If a relation is confluent, in a sense, specific paths don't matter since you can alway rejoin at a future destination.


\begin{figure}
  Triangle Property
  
  $\forall{\color{red}m},{\color{red}m'}.\:{\color{red}m\Rrightarrow m'}\:\mathrm{implies}\:{\color{red}m'}{\color{blue}\Rrightarrow max\left(m\right)}$
  
  \begin{tikzcd}
  \mathbin{\color{red}m} \tarrow[red]{r} \arrow[lightgray]{d} & \mathbin{\color{red}m'} \tarrow[blue]{ld} \\
  \mathbin{\color{blue}max(m)}                  &              
  \end{tikzcd}
  
  Diamond Property
  
  $\forall{\color{red}m},{\color{red}m'},{\color{red}m''}.\:{\color{red}m\Rrightarrow m'}\:\wedge\:{\color{red}m\Rrightarrow m''}\:\mathrm{implies}\:{\color{red}m'}{\color{blue}\Rrightarrow max\left(m\right)}$
  
  \begin{tikzcd}
                 & {\color{red}m} \tarrow[red]{rd} \tarrow[red]{ld} \arrow[lightgray]{dd} &                \\
  {\color{red}m'} \tarrow[blue]{rd} &                                       & {\color{red}m''} \tarrow[blue]{ld} \\
                 & {\color{blue}max(m)}                                &               
  \end{tikzcd}
  
  Confluence
  
  $\forall{\color{red}m},{\color{red}n},{\color{red}n'}.\:{\color{red}m\Rrightarrow_{\ast}n}\:\wedge\:{\color{red}m\Rrightarrow_{\ast}n'}\:\mathrm{implies}\:\exists{\color{blue}n'''}.\:{\color{red}n}{\color{blue}\Rrightarrow_{\ast}{\color{blue}n'''}}\:\wedge\:{\color{red}n'}{\color{blue}\Rrightarrow{\color{blue}n'''}}$
  
  \begin{tikzcd}
  % TODO look into proper subscripting of arrow heads
                & {\color{red}m} \tarrow[red]{rd}[label={[pos=1,inner sep=0,outer sep=0]0:${\ast}$}]{} \tarrow[red]{ld}[label={[pos=1,inner sep=0,outer sep=0]0:${\ast}$}]{} &              \\
  {\color{red}n'}  \tarrow[blue]{rd}[label={[pos=1,inner sep=0,outer sep=0]0:${\ast}$}]{} &                         & {\color{red}n''} \tarrow[blue]{ld}[label={[pos=1,inner sep=0,outer sep=0]0:${\ast}$}]{} \\
                & {\color{blue}{\color{blue}n'''}}                      &                              
  \end{tikzcd}
  
  \todo[inline]{absorb these diagrams into the proofs}
  
  \caption{Rewriting Diagrams}
  \label{fig:shape-diagrams}
\end{figure}
  

Since type equivelence is defined by parallel reductions we can show confluence following the proof in \cite{TAKAHASHI1995120}\footnote{also well presented in \cite{KOKKE2020102440}}.
The approach is motivated by the diagrams in \Fref{shape-diagrams}.

First, we define a function $\textbf{max}$ in \Fref{surface-max-step}.
$\textbf{max}$ takes the maximum possible parallel step, such that if $m\Rrightarrow\,m'$ then $m'\Rrightarrow\,\textbf{max}\left(m\right)$. % and $m\Rrightarrow\,max\left(m\right)$.

\begin{figure}
\begin{tabular}{cccc}
$\textbf{max}($ & $\left(\mathsf{fun}\,f\,x\Rightarrow m\right)\,n$ & $)=$ & $\textbf{max}\left(m\right)\left[f\coloneqq\mathsf{fun}\,f\,x\Rightarrow \textbf{max}\left(m\right),x\coloneqq \textbf{max}\left(n\right)\right]$ \tabularnewline
  &   &   &  otherwise\tabularnewline
$\textbf{max}($ & $x$ & $)=$ & $x$ \tabularnewline
$\textbf{max}($ & $m::M$ & $)=$ & $\textbf{max}\left(m\right)$ \tabularnewline
$\textbf{max}($ & $\star$ & $)=$ & $\star$ \tabularnewline
$\textbf{max}($ & $\left(x:M\right)\rightarrow N$ & $)=$ & $\left(x:\textbf{max}\left(M\right)\right)\rightarrow \textbf{max}\left(N\right)$ \tabularnewline
$\textbf{max}($ & $\mathsf{fun}\,f\,x\Rightarrow m$ & $)=$ & $\mathsf{fun}\,f\,x\Rightarrow \textbf{max}\left(m\right)$ \tabularnewline
$\textbf{max}($ & $m\,n$ & $)=$ & $\textbf{max}\left(m\right)\,\textbf{max}\left(n\right)$ \tabularnewline
\end{tabular}
\caption{$\textbf{max}$}
\label{fig:surface-max-step}
\end{figure}

\todo{for example}

\begin{lem}
Triangle Property of $\Rrightarrow$

If $m\Rrightarrow\,m'$ then $m'\Rrightarrow \textbf{max}\left(m\right)$ .
\end{lem}

\begin{proof}
by induction on the derivation $m\Rrightarrow\,m'$, with the only interesting cases are where a reduction is not taken
\begin{casenv}
\item in the case of \rulename{\Rrightarrow-::} , $m'\Rrightarrow \textbf{max}\left(m\right)$
by \rulename{\Rrightarrow-::-red}
\item in the case of \rulename{\Rrightarrow-\mathsf{fun}-app} , $m'\Rrightarrow \textbf{max}\left(m\right)$
by \rulename{\Rrightarrow-\mathsf{fun}-app-red} \todo{fix formatting}
\end{casenv}
\end{proof}
\begin{lem}
Diamond Property of $\Rrightarrow$

If $m\Rrightarrow\,m'$, $m\Rrightarrow\,m''$, implies $m'\Rrightarrow\,\textbf{max}\left(m\right)$
,$m''\Rrightarrow\,\textbf{max}\left(m\right)$ . 
\end{lem}

\begin{proof}
By thr triangle property.
  % Since $\textbf{max}\left(m\right)=\textbf{max}\left(m\right)$ . 
\end{proof}
\begin{thm}
Confluence of $\Rrightarrow_{\ast}$ 

If $m\Rrightarrow_{\ast}\,n'$, $m\Rrightarrow_{\ast}\,n''$, then
there exists $n'''$ such that $n'\Rrightarrow\,n'''$ ,$n''\Rrightarrow\,n'''$
.
\end{thm}

\begin{proof}
by repeated application of the diamond property.
\end{proof}
It follows that
\begin{thm}
$\equiv$ is transitive

If $m\equiv m'$ and $m'\equiv m''$ then $m\equiv m''$
\end{thm}

\begin{proof}
Since if $m\equiv m'$ and $m'\equiv m''$ then by definition for some $n$, $n'$, $m\Rrightarrow_{\ast}n$, $m'\Rrightarrow_{\ast}n$ and $m'\Rrightarrow_{\ast}n'$, $m''\Rrightarrow_{\ast}n'$. If $m'\Rrightarrow_{\ast}n$ and $m'\Rrightarrow_{\ast}n'$.
Then by confluence there exists some $p$ such that $n\Rrightarrow_{\ast}p$ and $n'\Rrightarrow_{\ast}p$.
By transitivity $m\Rrightarrow_{\ast}p$ and $m''\Rrightarrow_{\ast}p$.
So by definition $m\equiv m''$.
\todo{clean up, diagram}
\end{proof}
\begin{fact}
$\equiv$ is an equivalence relation.
\end{fact}


\subsubsection{Stability}
Next we must confirm that type constructors are stable over parallel reduction.
Specifically, $\left(x:N\right)\rightarrow M\cancel{\equiv}\star$.
If type constructors are associated, the entire $\equiv$ relation is degenerate.
Since defintitional equality is defined in terms of reduction, it is sufficient to show that $\left(x:N\right)\rightarrow M\cancel{\Rrightarrow}\star$.
We will prove slightly stronger lemmas about reduction that confirms this fact.

\begin{lem}
Stability of $\rightarrow$ over $\Rrightarrow_{\ast}$

$\forall N,M,P.\left(x:N\right)\rightarrow M\Rrightarrow_{\ast}P\:\mathrm{implies}\:\exists N',M'.P=\left(x:N'\right)\rightarrow M'\land N\Rrightarrow_{\ast}N'\land M\Rrightarrow_{\ast}M'$
\end{lem}

\begin{proof}
by induction on $\Rrightarrow_{\ast}$
\begin{casenv}
  \item $\rulename{\Rrightarrow_{\ast}-refl}$ follows directly
  \item $\rulename{\Rrightarrow_{\ast}-trans}$ via the induction hypothesis and noting only the $\rulename{\Rrightarrow-\mathsf{fun}-ty}$ rule is possible as a step
\end{casenv}
\end{proof}
Therefore the we can derive an important fact about $\equiv$
\begin{cor}
Stability of $\rightarrow$ over $\equiv$
the following rule is admissible
\[
\frac{\left(x:N\right)\rightarrow M\equiv\left(x:N'\right)\rightarrow M'}{N\equiv N'\quad M\equiv M'}
\]
\end{cor}

\begin{proof}
By the definition of $\equiv$ and the lemma above.
\end{proof}

\subsection{Preservation}

A useful property of a type systems is that evaluation preserves type\footnote{
   Similar proofs for dependent type systems can be found in Chapter 3 of \cite{luo1994computation}, Section 3.1 of \cite{10.1007/3-540-45413-6_27}(including eta expansion in an implicit system), in the appendix of \cite{sjoberg2012irrelevance}, and formalized in the the examples of Autosubst\cite{SchaeferEtAl:2015:Autosubst:-Reasoning}.
   }.
\todo{push this further up?}

We need several more technical lemmas before we can prove that $\Rrightarrow_{\ast}$ is type preserving.
The lemmas needed are almost always on induction by typing derivations.
% this allows the context to grow under the inductive hypothesis while still being well founded by the tree structure of the derivation. 

\subsubsection{Structural Properties}

% unneeded: In many cases lemmas will produce derivations that are equal or smaller in height to one of the derivations used in their input, so that inductions can be performed on the output of the lemma while still being well founded.
\begin{thm}
Context Weakening

The following rule is admissible
\[
\frac{\Gamma\tasys n:N}{\Gamma,\Gamma'\tasys n:N}
\]
\end{thm}

\begin{proof}
by induction on typing derivations
\end{proof}
\begin{lem}
Substitution Preservation

The following rule is admissible\footnote{
  This lemma is sufficient for our informal account of variable substitution and binding.
  A fully formal account will be sensitive to the specific binding strategy, and may need to prove this lemma as a corollary from simultaneous substitutions}
\[
\frac{\Gamma\tasys n:N\quad\Gamma,x:N,\Gamma'\tasys m:M}{\Gamma,\Gamma'\left[x\coloneqq n\right]\tasys m\left[x\coloneqq n\right]:M\left[x\coloneqq n\right]}
\]
\end{lem}

\begin{proof}
by induction on typing derivations

\begin{casenv}
  \item \rulename{ty-var} follows by weakening the substituted term
  \item \rulename{ty-conv} follows from $\equiv\rulename{-Def}$ and that $\Rrightarrow_{\ast}$ is closed under substitution
  \item All other cases follow directly or by induction
\end{casenv}
\end{proof}
When contexts are convertible, typing judgments still hold.
We extend the notion of definitional equality to contexts in \Fref{surface-Context-Equiv}.

\begin{figure}
\[
\frac{\ }{\lozenge\equiv\lozenge}\,\rulename{\equiv-ctx-empty}
\]

\[
\frac{\Gamma\equiv\Gamma'\quad M\equiv M'}{\Gamma,x:M\equiv\Gamma',x:M'}\,\rulename{\equiv-ctx-ext}
\]

\caption{Definitionally Equal Contexts}
\label{fig:surface-Context-Equiv}
\end{figure}

\begin{lem}
Context Preservation

the following rule is admissible
\[
\frac{\Gamma\tasys n:N\quad\Gamma\equiv\Gamma'}{\Gamma'\tasys n:N}
\]
\end{lem}

\begin{proof}
by induction over typing derivations

\begin{casenv}
  \item \rulename{ty-var} follows since $\equiv$ is symmetric
% \item \rulename{ty-\mathsf{fun}-ty} and \rulename{ty-\mathsf{fun}} ...
  \item All other cases follow directly or by induction
\end{casenv}
\end{proof}

\subsubsection{Inversion Lemmas}
In the preservation proof we will need to reason backwards about the typing judgments implied by a typing derivation of term syntax.
However this induction does not go through directly, and the induction hypothesis must be extended to definitional equality.

\begin{lem}
$\mathsf{fun}$-Inversion (generalized)

\[
\frac{\Gamma\tasys\mathsf{fun}\,f\,x\Rightarrow m\,:\,P\quad P\equiv\left(x:N\right)\rightarrow M}{\Gamma,f:\left(x:N\right)\rightarrow M,x:N\tasys m:M}
\]

is admissible. 
\end{lem}

\begin{proof}
By induction on typing derivations,

\begin{casenv}
  \item \rulename{ty-\mathsf{fun}} follows by the stability of \rulename{ty-\mathsf{fun}} and preservation of contexts
  \item \rulename{ty-conv} follows by transitivity of $\equiv$ and induction
  \item All other cases impossible
\end{casenv}

\end{proof}
This allows us to conclude the more straightforward corollary 
\begin{cor}
$\mathsf{fun}$-Inversion

\[
\frac{\Gamma\tasys\mathsf{fun}\,f\,x\Rightarrow m\,:\,\left(x:N\right)\rightarrow M}{\Gamma,f:\left(x:N\right)\rightarrow M,x:N\tasys m:M}
\]
\end{cor}

\begin{proof}
by noting that $\left(x:N\right)\rightarrow M\equiv\left(x:N\right)\rightarrow M$, by reflexivity 
\end{proof}
%TODO: Note that the result of this lemma will always produce derivations of equal or smaller height to the input typing derivation.
% unneeded
\begin{thm}
$\Rrightarrow$-Preservation 

The following rule is admissible
\[
\frac{\Gamma\tasys m:M\quad m\Rrightarrow m'}{\Gamma\tasys m':M}
\]
\end{thm}

\begin{proof}
by induction on the typing derivation $\Gamma\tasys m:M$, specializing on $m\Rrightarrow m'$,
\todo{formatting}
\begin{casenv}
  \item \rulename{ty-::} when \rulename{\Rrightarrow-::}, we must show $\Gamma\tasys m'::M':\,M$.
  %  from $m\Rrightarrow m'$, $M\Rrightarrow M'$, and $\Gamma\tasys m'\,:\,M$.
   \newline
   \begin{tabular}{ll}
    $\Gamma\tasys m'\,:\,M$ & by induction\tabularnewline
    $M\equiv M'$ & by $M\Rrightarrow M'$\tabularnewline
    $\Gamma\tasys m'\,:\,M'$ & by \rulename{ty-conv}\tabularnewline
    $\Gamma\tasys m'::M':\,M'$ & by \rulename{ty-::}\tabularnewline
    $M'\equiv M$ & by symmetry\tabularnewline
    $\Gamma\tasys m'::M':\,M$ & by \rulename{ty-conv}\tabularnewline
  \end{tabular}
  \item \rulename{ty-\mathsf{fun}-ty} when \rulename{\Rrightarrow-\mathsf{fun}-ty} by preservation of contexts
  \item \rulename{ty-\mathsf{fun}-app} when \rulename{\Rrightarrow-\mathsf{fun}-app-red}, we must show 
    \newline
    $\Gamma\tasys m'\left[f\coloneqq\mathsf{fun}\,f\,x\Rightarrow m',x\coloneqq n'\right]:M\left[x\coloneqq n\right]$
    \newline
     from $\Gamma\tasys n\,:\,N$, $\Gamma\tasys\mathsf{fun}\,f\,x\Rightarrow m\,:\,\left(x:N\right)\rightarrow M$, $m\Rrightarrow m'$, and $n\Rrightarrow n'$.
  \newline
  \begin{tabular}{ll}
    $\mathsf{fun}\,f\,x\Rightarrow m\Rrightarrow\mathsf{fun}\,f\,x\Rightarrow m'$ & by \rulename{\Rrightarrow-\mathsf{fun}}\tabularnewline
    $\Gamma\tasys\mathsf{fun}\,f\,x\Rightarrow m'\,:\,\left(x:N\right)\rightarrow M$ & by induction\tabularnewline
    $\Gamma,f:\left(x:N\right)\rightarrow M,x:N\tasys m'$ & by fun-inversion\tabularnewline
    $\Gamma\tasys n'\,:\,N$ & by induction\tabularnewline
    \makecell[l]{$\Gamma\tasys m'\left[f\coloneqq\mathsf{fun}\,f\,x\Rightarrow m',x\coloneqq n'\right]$\\$\ :M\left[x\coloneqq n'\right]$} & by substitution preservation \tabularnewline
    $M\left[x\coloneqq n'\right]\equiv M\left[x\coloneqq n\right]$ & by substitution by steps\tabularnewline
    \makecell[l]{$\Gamma\tasys m'\left[f\coloneqq\mathsf{fun}\,f\,x\Rightarrow m',x\coloneqq n'\right]$\\$\ :M\left[x\coloneqq n\right]$} & by \rulename{ty-conv}\tabularnewline
  \end{tabular}
  \item \rulename{ty-\mathsf{fun}-app} when \rulename{\Rrightarrow-\mathsf{fun}-app}, we must show 
  \newline
  $\Gamma\tasys m'\,n':\,M\left[x\coloneqq n\right]$ from $\Gamma\tasys n\,:\,N$, $\Gamma\tasys m\,:\,\left(x:N\right)\rightarrow M$, $m\Rrightarrow m'$, $n\Rrightarrow n'$
  \newline
  \begin{tabular}{ll}
    $n\Rrightarrow n'$ & \tabularnewline
    $\Gamma\tasys m'\,:\,\left(x:N\right)\rightarrow M$ & by induction\tabularnewline
    $\Gamma\tasys n'\,:\,N$ & by induction\tabularnewline
    $\Gamma\tasys m'\,n':\,M\left[x\coloneqq n'\right]$ & \rulename{ty-\mathsf{fun}-app}\tabularnewline
    $M\left[x\coloneqq n'\right]\equiv M\left[x\coloneqq n\right]$ & by substitution by steps\tabularnewline
    $\Gamma\tasys m'\,n':\,M\left[x\coloneqq n\right]$ & \rulename{ty-conv}\tabularnewline
  \end{tabular}
  \item All other cases follow directly or by induction
\end{casenv}
\end{proof}

\subsection{Progress}

The second key theorem to show is called progress.
For a well typed term in an empty context, then a further step can be taken or computation is finished.
For non-dependently typed programming languages, these steps are easy to characterize, but for dependent types there are issues.\todo{awk}
If we characterize computation with the $\Rrightarrow$ relation, the progress lemma holds in a meaningless way since we can always take a reflexive step.
Thus a less reflexive relation is needed.
Ideally the relation should also be deterministic and a sub relation of $\Rrightarrow_{*}$.
We can choose a call-by-value relation since this meets all the properties required, and is a standard execution strategy that reflects actual implementations.

\begin{figure}
\begin{tabular}{lcl}
\multicolumn{3}{l}{values,}\tabularnewline
v & $\Coloneqq$ & $\star$\tabularnewline
  & $|$ & $\left(x:M\right)\rightarrow N$\tabularnewline
  & $|$ & $\mathsf{fun}\,f\,x\Rightarrow m$\tabularnewline
\end{tabular}\caption{Surface Language Value Syntax}
\label{fig:surface-value-syntax}
\end{figure}

Values are characterized by the sub-grammar in \Fref{surface-value-syntax}.
As usual, functions with any body are values.
Additionally the Type universe is a value, and function types are values.

\begin{figure}
\[
\frac{\,}{\left(\mathsf{fun}\,f\,x\Rightarrow m\right)v\rightsquigarrow m\left[f\coloneqq\mathsf{fun}\,f\,x\Rightarrow m,x\coloneqq v\right]}
\]

\[
\frac{m\rightsquigarrow m'}{m\,n\rightsquigarrow m'\,n}
\]

\[
\frac{n\rightsquigarrow n'}{v\,n\rightsquigarrow v\,n'}
\]

\[
\frac{m\rightsquigarrow m'}{m::M\rightsquigarrow m'::M}
\]

\[
\frac{\,}{v::M\rightsquigarrow v}
\]

\caption{Surface Language Call-by-Value reductions}
\label{fig:surface-reduction-step}
\end{figure}

A call-by-value relation is defined in \Fref{surface-reduction-step}.
The reductions are standard for a call-by-value lambda calculus, except that type annotations are only removed from values.

\todo{explicitly define stuck}
\begin{fact}
$\rightsquigarrow$ implies $\Rrightarrow$

the following rule is admissible

\[
\frac{m\rightsquigarrow m'}{m\Rrightarrow m'}
\]
\end{fact}

Thus $\rightsquigarrow$ also preserves types.

We will need a technical lemma that determines the syntax a value of function type must be in an empty context

\begin{lem}
  $\mathsf{fun}$-Canonical form (generalized)
  If $\tasys v\,:\,P$ and $P\equiv\left(x:N\right)\rightarrow M$ then $v=\mathsf{fun}\,f\,x\Rightarrow m$.
\end{lem}
\begin{proof}
by induction on the typing derivation

\begin{casenv}
\item \rulename{ty-\mathsf{fun}} follows immediately
\item \rulename{ty-conv} by the equivelence of $\equiv$ and induction
\item \rulename{ty-\star}, \rulename{ty-\mathsf{fun}-ty} are impossible, by the stability of $\equiv$
\item other rules  are impossible, since they do not type values
\end{casenv}
\end{proof}
as a corollary,
\begin{cor}
$\mathsf{fun}$-Canonical form (generalized)

If $\tasys v\,:\,\left(x:N\right)\rightarrow M$ then \textup{$v=\mathsf{fun}\,f\,x\Rightarrow m$.}
\end{cor}

\todo{note that by only considering values, we can avoid the problematic
application case}

Finally we can prove the progress theorem.
\begin{thm}
Progress 

If $\tasys m\,:\,M$ then $m$ is a value or there exists $m'$ such that $m\rightsquigarrow m'$
\end{thm}

\begin{proof}
As usual this follows form induction on the typing derivation

\begin{casenv}
  \item \rulename{ty-\star}, $\star$ is a value 
  \item \rulename{ty-var}, impossible in an empty context
  \item \rulename{ty-conv}, by induction
  \item \rulename{ty-::}, we have a typing derivation concluding $\tasys m::M\,:\,M$.
  By induction, $m$ is a value or there exists $m'$ such that $m\rightsquigarrow m'$.
  \begin{casenv}
    \item if $m$ is a value, then $m::M\rightsquigarrow m$ 
    \item if $m\rightsquigarrow m'$,then $m::M\rightsquigarrow m'::M$
  \end{casenv}
  \item \rulename{ty-\mathsf{fun}-ty}, $\left(x:M\right)\rightarrow N$ is a value
  \item \rulename{ty-\mathsf{fun}}, $\mathsf{fun}\,f\,x\Rightarrow m$ is a value
  \item \rulename{ty-\mathsf{fun}-app}, we have a typing derivation concluding $\tasys m\,n\ :\ M\left[x\coloneqq n\right]$ with the premisies $\tasys m\,:\,\left(x:N\right)\rightarrow M$, $\Gamma\tasys n\,:\,N$.
  By induction, $m$ is a value or there exists $m'$ such that $m\rightsquigarrow m'$.
  By induction, $n$ is a value or there exists $n'$ such that $n\rightsquigarrow n'$.
  \begin{casenv}
    \item if $m\rightsquigarrow m'$, then $m\,n\rightsquigarrow m'\,n$
    \item if $m$ is a value, and $n\rightsquigarrow n'$,  then $m\,n\rightsquigarrow m\,n'$
    \item if $m$ is a value, and $n$ is a value, then $m=\mathsf{fun}\,f\,x\Rightarrow p$ by canonical forms of functions.
      The term steps $\left(\mathsf{fun}\,f\,x\Rightarrow p\right)n\rightsquigarrow p\left[f\coloneqq\mathsf{fun}\,f\,x\Rightarrow p,x\coloneqq n\right]$
  \end{casenv}
\end{casenv}

\end{proof}
\todo{awk}
Progress via call-by-value can be seen as a specific sub-strategy of $\Rrightarrow$.
An interpreter is always free to take any $\Rrightarrow$, but if it is unclear which $\Rrightarrow$ to take, either it is a value and no further steps are required, or can fall back on $\rightsquigarrow$ until the the outermost computation has completed.

\subsection{Type Soundness}

The language has type soundness, well typed terms will never ``get stuck'' in the surface language.
This follows by iterating the progress and preservation lemmas.

\todo{be explicit about the disconnect between type computation via par, and term level cbv}

% \todo{other lemmas not needed for this proof, par max is par, inversions?}


\subsection{Regularity}
The rules in \Fref{surface-TAS} allow for invalid constructions in the context.
For instance, $x:1_{c}\tasys...$ is allowed by the context grammar.
Additionally, it is not required that both ends of a conversion are well typed.
For instance, $\tasys\ \star\ :\ (\lambda - \Rightarrow \star)\,(\star\,\star)$ is typeable by conversion.


\begin{figure}
\[
\frac{\Gamma\,\mathbf{ok}\quad x:M\in\Gamma}{\Gamma\tasysr{}x\,:\,M}\,\rulename{ty-var}
\]

\[
\frac{\Gamma\tasysr{}m\,:\,M}{\Gamma\tasysr{}m::M\,:\,M}\,\rulename{ty-::}
\]

\[
\frac{\Gamma\,\mathbf{ok}}{\Gamma\tasysr{}\star\,:\,\star}\,\rulename{ty-\star}
\]

\[
\frac{\Gamma\tasysr{}M\,:\,\star\quad\Gamma,x:M\tasysr{}N\,:\,\star}{\Gamma\tasysr{}\left(x:M\right)\rightarrow N\,:\,\star}\,\rulename{ty-\mathsf{fun}-ty}
\]

\[
\frac{\Gamma\tasysr{}m\,:\,\left(x:N\right)\rightarrow M\quad\Gamma\tasysr{}n\,:\,N}{\Gamma\tasysr{}m\,n\,:\,M\left[x\coloneqq n\right]}\,\rulename{ty-\mathsf{fun}-app}
\]

\[
\frac{\Gamma,f:\left(x:N\right)\rightarrow M,x:N\tasysr{}m\,:\,M}{\Gamma\tasysr{}\mathsf{fun}\,f\,x\Rightarrow m\,:\,\left(x:N\right)\rightarrow M}\,\rulename{ty-\mathsf{fun}}
\]

\[
\frac{\Gamma\tasysr{}m\,:\,M\quad\Gamma\tasysr{}M\equiv M'\,:\,\star}{\Gamma\tasysr{}m\,:\,M'}\,\rulename{ty-conv}
\]

\[
\frac{\Gamma\tasysr{}m\,:\,M\quad\Gamma\tasysr{}m'\,:\,M\quad m\Rrightarrow m''\quad m'\Rrightarrow m''}{\Gamma\tasysr{}m\equiv m'\,:\,M}\,\rulename{def}
\]

\[
\frac{\ }{\lozenge\,\mathbf{ok}}\,\rulename{emp-ok}
\]

\[
\frac{\Gamma\tasysr{}M:\star\quad\Gamma\,\mathbf{ok}}{\Gamma,x:M\,\mathbf{ok}}\,\rulename{emp-ok}
\]
\caption{Type assignment system (regular)}
\label{fig:surface-tas-reg}
\end{figure}

Though these restrictions are not required for type soundness, it will be convenient to exclude these possibilities by adding additional restrictions to the \ac{TAS}.
The updated system is presented in \Fref{surface-tas-reg}.
The $\mathbf{ok}$ forces contexts to only contain well typed types.
The new conversion rule, restricts conversion to well typed types.


Given these restrictions we can conclude some convineint regularity properties.
\begin{thm}
  Regularity
  
  If $\Gamma\tasysr{}m:M$ then $\Gamma\tasysr{}M:\star$ and $\Gamma\,\mathbf{ok}$
\end{thm}
\begin{proof}
  by induction on typing derivations
\end{proof}




\begin{conjecture}
The regular system has progress and preservation it is type sound
\end{conjecture}

Additionally, 


It is possible to prove type soundness directly but it involves a more subtle mutual induction.

Given this we will use the regular system from now on without subscript.


% There is some question about how much typing information should be coupled to the judgment, forcing contexts to be well formed eliminates nonsense situations like $x:1_{c}\vdash...$ by construction, but requires more fork when forming judgments that can be distracting.
% The proofs in this section can be done without forcing the context to be well formed, the additional constraints are omitted.
% \todo[inline]{regularity!}

\subsection{Type checking is impractical}

This type system is inherently non-local.
No type annotations are ever required to form a typing derivation.
That means it would be up to a type checking algorithm to guess the types of intermediate terms.
For instance, 

\begin{align*}
\lambda f\Rightarrow & \,\\
... & f\,1_{c}\,true_{c}\\
... & f\,0_{c}\,1_{c}
\end{align*}
  
what should be deduced for the type of $f$? One possibility is $f:\left(n:\mathbb{N}\right)\rightarrow n\,\star\,\left(\lambda-\Rightarrow\mathbb{N}_{c}\right)\,\mathbb{B}_{c}\rightarrow...$.
But there are infinitely other possibilities.
Worse, if there is an error, it may be impossible to localize to a specific region of code.
To make a practical type checker we need to insist that the user include some type annotations.

\section{\Bidir{} Surface Language}

% Annotate all the vars 
There are many possible ways to localize the type checking process.
We could ask that all variables be annotated at binders.
This is enticing from a theoretical perspective, since it matches how type contexts are built up.

However note that, our proof of $\lnot1_{c}\doteq_{\mathbb{N}_{c}}0_{c}$ will look like

$\lambda pr\underline{:1_{c}\doteq_{\mathbb{N}_{c}}0_{c}}\Rightarrow pr\,\left(\lambda n:\underline{\left(C:\left(\mathbb{N}_{c}\rightarrow\star\right)\right)\rightarrow C\,1_{c}\rightarrow C\,0_{c}}\Rightarrow n\,\star\,(\lambda-:\underline{\star\Rightarrow Unit_{c}})\,\perp_{c}\right)\,tt_{c}:\underline{\lnot1_{c}\doteq_{\mathbb{N}_{c}}0_{c}}$

More than half of the term is type annotations!
Annotating every binding site requires a lot of redundant information.
% Further the theory would need to deal with all the binders evaluating
Luckily there's a better way.

\subsection{\Bidir{} Type Checking}

\textbf{\Bidir{} type checking} is a popular form of lightweight type inference, which strikes a good compromise between the required type annotations and the simplicity of the procedure, allowing for localized errors\footnote{\cite{christiansen2013\bidir{}} is a good tutorial, \cite{10.1145/3450952} is a survey of the technique}.
In the usual \bidir{} typing schemes, annotations are only required at the top-level, or around a function that is directly applied to an argument\footnote{more generally when an elimination reduction is possible.}.
For example $(\lambda x\Rightarrow x+x)7$ would need to be written $\left((\lambda x\Rightarrow x+x)::\mathbb{N}\rightarrow\mathbb{N}\right)7$.
Since programers rarely write functions that are immediately evaluated, this style of type checking usually only needs top level functions to be annotated\footnote{Even in Haskell, with full Hindley-Milner type inference, top level type annotations are encouraged.}\todo{ref style guide.
the point was similarly made in Agda thesis.}.
In fact, almost every example in \Fref{surface-examples} has enough annotations to type check \bidir{}{}ly without further information.

\todo{note popularity}

This is accomplished by breaking the typing judgments into two mutual judgments:
\begin{itemize}
\item \textbf{Type Inference} where type information propagates out of a term, $\overrightarrow{\,:\,}$ in our notation. 
\item \textbf{Type Checking} judgments where a term is checked against a type, $\overleftarrow{\,:\,}$ in our notation. 
\end{itemize}
This allows typing information to flow from the "outside in" for type checking judgments and "inside out" for the type inference judgments.
A check can be induced manually with a type annotation.
When an inference meets a check, a conversion verifies that the types are definitionally equal.
This has the advantage of precisely limiting where the $\operatorname{ty-conv}$ rule is needed, since conversion checking is usually an inefficient part of dependent type checking.

This enforced flow of information results in a system that localizes type errors.
If a type was inferred, it was unique from the term, so it can be used freely.
Checking judgments force terms that could have multiple typings in the \ac{TAS} to have at most one type.

\begin{figure}
\[
\frac{x:M\in\Gamma}{\Gamma\vdash x\overrightarrow{\,:\,}M}\operatorname{\overrightarrow{ty}-var}
\]
\[
\frac{\,}{\Gamma\vdash\star\overrightarrow{\,:\,}\star}\operatorname{\overrightarrow{ty}-\star}
\]
\[
\frac{\Gamma\vdash m\overleftarrow{\,:\,}M}{\Gamma\vdash m::M\overrightarrow{\,:\,}M}\operatorname{\overrightarrow{ty}-::}
\]
\[
\frac{\Gamma\vdash M\overleftarrow{\,:\,}\star\quad\Gamma,x:M\vdash N\overleftarrow{\,:\,}\star}{\Gamma\vdash\left(x:M\right)\rightarrow N\overrightarrow{\,:\,}\star}\operatorname{\overrightarrow{ty}-\mathsf{fun}-ty}
\]
\[
\frac{\Gamma\vdash m\overrightarrow{\,:\,}\left(x:N\right)\rightarrow M\quad\Gamma\vdash n\overleftarrow{\,:\,}N}{\Gamma\vdash m\,n\overrightarrow{\,:\,}M\left[x\coloneqq n\right]}\operatorname{\overrightarrow{ty}-\mathsf{fun}-app}
\]
\[
\frac{\Gamma,f:\left(x:N\right)\rightarrow M,x:N\vdash m\overleftarrow{\,:\,}M}{\Gamma\vdash\mathsf{fun}\,f\,x\Rightarrow m\overleftarrow{\,:\,}\left(x:N\right)\rightarrow M}\operatorname{\overleftarrow{ty}-\mathsf{fun}}
\]
\[
\frac{\Gamma\vdash m\overrightarrow{\,:\,}M\quad M\equiv M'}{\Gamma\vdash m\overleftarrow{\,:\,}M'}\operatorname{\overleftarrow{ty}-conv}
\]

\caption{Surface Language \Bidir{} Typing Rules}
\label{fig:surface-bityping-rules}
\end{figure}

% review the typing rule 
The surface language supports \bidir{} type-checking over the pre-syntax with the rules in \Fref{surface-bityping-rules}.
The rules are almost the same as before except that typing direction is now explicit in the judgment.

As mentioned, \bidir{} type checking handles higher order functions very well.
For instance, the expression $\vdash(\lambda x\Rightarrow x\,(\lambda y\Rightarrow y)\,2)\overleftarrow{\,:\,}\left(\left(\mathbb{N}\rightarrow\mathbb{N}\right)\rightarrow\mathbb{N}\rightarrow\mathbb{N}\right)\rightarrow\mathbb{N}$ checks because $\vdash(\lambda y\Rightarrow y)\overleftarrow{\,:\,}\left(\mathbb{N}\rightarrow\mathbb{N}\right)$ and $\vdash2\overleftarrow{\,:\,}\mathbb{N}$.

Unlike the undirected judgments of the Type Assignment System, the inference rule of the \bidir{} system does not convert
The inference, it is unique up to syntax!
For example $x:Vec\,3\vdash x\overrightarrow{\,:\,}Vec\,3$, but $x:Vec\,3\cancel{\vdash}x\overrightarrow{\,:\,}Vec\,\left(1+2\right)$.
This could cause unexpected behavior around function applications.
For instance, if $\Gamma\vdash m\overrightarrow{\,:\,}\mathbb{N}\rightarrow\mathbb{N}$ then $\Gamma\vdash m\:7\overrightarrow{\,:\,}\mathbb{N}$ will infer, but only because the $\rightarrow$ is in the head position of the type $\mathbb{N}\underline{\rightarrow}\mathbb{N}$.
If $\Gamma\vdash m\overrightarrow{\,:\,}\left(\mathbb{N}\rightarrow\mathbb{N}::\star\right)$ then $::$ is in the head position of $\mathbb{N}\rightarrow\mathbb{N}\underline{::}\star$ and $\Gamma\cancel{\vdash}m\ 7\overrightarrow{\,:\,}\mathbb{N}$ will will not infer.

The similar issue is possible around check rules around function definitions.
For instance, $\vdash\left((\lambda x\Rightarrow x)::\mathbb{N}\rightarrow\mathbb{N}\right)\ \overrightarrow{\,:\,}\mathbb{N}\rightarrow\mathbb{N}$ will infer, but if computation blocks the $\rightarrow$ from being in the head position, inference will be impossible.
As in the expression, $\left((\lambda x\Rightarrow x)::\left(\mathbb{N}\rightarrow\mathbb{N}\underline{::}\star\right)\right)$ which will not infer.

For these reasons, realistic implementations will often evaluate the types needed for $\overleftarrow{ty}-\mathsf{fun}$, and $\operatorname{\overrightarrow{ty}-\mathsf{fun}-app}$ into weak head normal form\footnote{as in \cite{COQUAND1996167}}.
More advanced \bidir{} implementations such as Agda\cite{norell2007towards} even perform unification as part of their \bidir{} type checking.

\todo[inline]{alternative listed in appendix}
\todo[inline]{what else does the algorithm infer not listed here}
\todo[inline]{More about extending the system so constraint solving can happen under a check judgment }
\todo[inline]{Clearly explain why this is needed for the cast system, annotating every var is cumbersome, constraint solving is iffy when things may be undecidable}

This document opts for the simplest possible presentation of \bidir{} type checking.
There will always be ways to make type inference more powerful, at the cost of complexity.

\subsection{The \Bidir{} System is Type Sound}

It is possible to prove \bidir{} type systems are type sound directly\cite{nanevski2005dependent}.
But it would be difficult for the system described here since type annotations evaluate away, complicating preservation.
Alternatively we can show that a \bidir{} typing judgment implies a type assignment system typing judgment.

\begin{thm}
\Bidir{} implies \ac{TAS}

if $\Gamma\vdash m\overrightarrow{\,:\,}M$ then $\Gamma\vdash m\,:\,M$

if $\Gamma\vdash m\overleftarrow{\,:\,}M$ then $\Gamma\vdash m\,:\,M$
\end{thm}

\begin{proof}
by mutual induction on the \bidir{} typing derivations.
\end{proof}
Therefore the \bidir{} system is also type sound.

\subsection{The \ac{TAS} System is weakly annotatable by the \Bidir{} System}

In \Bidir{} systems, \textbf{annotatability}\footnote{also called \textbf{completeness}} is the property that any expression that types in a \ac{TAS} will type in the \bidir{} system with only additional annotations.
This property doesn't exactly hold for the \bidir{} system presented here.
For instance, $\vdash\left((\lambda x\Rightarrow x)::\left(\mathbb{N}\rightarrow\mathbb{N}::\star\right)\right)$ type checks in the \ac{TAS} system, but no amount of annotations will make it check in the \bidir{} system.
Instead we can show that the \bidir{} system does not preclude any computation available in the \ac{TAS}, though annotations may need to be added (or removed).% no need to remove if properly \bidir{}).
We will call this property \textbf{weak annotatability}.
\begin{thm}
weak annotatability.

if $\Gamma\vdash m\,:\,M$ then $\Gamma\vdash m'\overleftarrow{\,:\,}M'$, $m\equiv m'$ and $M\equiv M'$ 

if $\Gamma\vdash m\,:\,M$ then $\Gamma\vdash m'\overrightarrow{\,:\,}M'$ , $m\equiv m'$ and $M\equiv M'$
\end{thm}

\begin{proof}
by induction on the typing derivation, adding and removing annotations at each step that are convertible with the original $m$
\end{proof}
\todo[inline]{slight changes have been made, double check this}

\subsection{Absent Logical Properties}

When type systems are used as logics, it is desirable that
\begin{itemize}
\item There exists a type that is uninhabited in the empty context, so the system is \textbf{logically consistent}\footnote{also called \textbf{logically sound}}.
\item Type checking is decidable.
\end{itemize}
Neither the \ac{TAS} system or the \Bidir{} systems has these properties\footnote{These properties are usually shown by showing that the computation that generates definitional equality is normalizing.
A proof for a more logical system can be found in Chapter 4\cite{luo1994computation}.
Another excellent tutorial can be found in Chapter 2 in \cite{casinghino2014combiningthesis}}.
% aparently that note from Chris Casinghino is dead http://prosecco.gforge.inria.fr/personal/hritcu/temp/snforcc.pdf

\subsubsection{Logical Inconsistency}

The surface language is logically inconsistent, since every type is inhabited.

\begin{example}
Every Type is Inhabited (by recursion)

$\mathsf{fun}\,f\,x\Rightarrow f\,x\qquad:\perp_{c}$
\end{example}

It is possible to encode Girard's paradox, producing another source of logical unsoundness.
\begin{example}
Every Type is Inhabited (by \tit{})

\todo{full example}

\todo{cite stuff (see https://stackoverflow.com/questions/18178999/do-agda-programs-necessarily-terminate), of course this hapens in Girard's french thesis}
\end{example}

A subtle form of recursive behavior can be built out of Gerard's paradox\cite{Reinhold89typecheckingis}, but this behavior is no worse than the unrestricted recursion already allowed.

% I am unaware of anyone accidentally deriving a falsehood from \tit{}.

Operationally, logical inconsistency will be recognized by programmers as non-termination.
Non-termination seems not to matter for programming languages in practice.
For instance, in ML the type $\mathtt{f:Int->Int}$ does not imply the termination of $\mathtt{f\,2}$.
While unproductive non-termination is always a bug, it seems an easy bug to detect and fix when it occurs.
In mainstream languages, types help to communicate the intent of termination, even though termination is not guaranteed by the type system.
Importantly, no desirable computation is prevented in order to preserve logical consistency.
There will never be a way to allow all the terminating computations and exclude all the nonterminating computations.
A tradeoff must be made, and programmers likely care more about having all possible computations than preventing non-termination.
Therefore, logical unsoundness seems suitable for a dependently typed programming language.

\todo{argue from the Blum proof?  Allowing non-termination makes writing termination programs easier.}

\todo{add ref to inequalities}

While the surface language supports proofs, not every term typed in the surface language is a proof.
Terms can still be called proofs as long as the safety of recursion and \tit{} are checked externally.
In this sense, the listed example inequalities are proofs, as they make no use of general recursion (so all recursions are well founded) and universes are used in a safe way (universe hierarchies could be assigned).
In an advanced implementation, an automated process could supply warnings when constructs are used in potentially unsafe ways.
Traditional software testing can be used to discover if there are actual proof bugs.
Even though the type system is not logically consistent, type checking still eliminates a large class of possible mistakes.
While it is possible to make a subtle error, it is easier to make an error in a paper and pencil proofs, or in typeset \LaTeX.

Finally by separating non-termination concerns from the core of the theory, this architecture is resilient to change.
If the termination checker is updated in Coq, there is some chance older proof scripts will no longer type check.
With the architecture proposed here, code will always have the same static and dynamic behavior, though some warnings might appear or disappear.

\subsubsection{Type Checking is Undecidable}
\begin{thm}
Type Checking is Undecidable
\end{thm}

\begin{proof}
Given a thunk $f:Unit$ defined in PCF, it can be encoded into the surface system as a thunk $f':Unit_{c}$, such that if $f$ reduces to the canonical $Unit$ then $f'\Rrightarrow_{\ast}\lambda A.\lambda a.a$ 

$\vdash\star:f'\,\star\,\star$ type-checks by conversion exactly when $f$ halts.

If there is a procedure to decide type checking we can decide exactly when any PCF function halts.
Since checking if a PCF function halts is undecidable, type checking here is undecidable.

\end{proof}
Decidability of type checking is often used as a proxy for efficient typechecking.

Again this the root of the problem is the non-termination that results by allowing as many computations as possible, which seem necessary in a realistic programming language.

Luckily undecidability of type checking is not as bad as it sounds for several reasons.
First, the pathological terms that cause non-terminating conversion are rarely created on purpose.
In the \bidir{} system, conversion checks will only happen at limited positions, and it is possible to use a counter to warn or give errors at code positions that do not convert because normalization takes too long.
Heuristic methods of conversion checking seem to work well enough in practice even without a counter.
It is also possible to embed proofs of conversion directly into the syntax\cite{sjoberg2012irrelevance}.

Many dependent type systems, such as Agda, Coq, and Lean, aspire to decidable type checking.
However these systems allow extremely fast growing functions to be encoded (such as Ackerman's function).
A fast growing function can generate a very large index that can be used to check some concrete but unpredictable property, (how many Turing machines whose code is smaller then $n$ halt in $n$ steps?).
When this kind of computation is lifted to the type level, type checking is computationally infeasible, to say the least.

\todo{make sure I'm not missing any langs, C\#...?}

Many mainstream programming languages have undecidable type checking.
If a language admits a sufficiently powerful macro or preprocessor system that can modify typing, this would make type checking undecidable (this makes the type system of C, C++\footnote{apparently even the grammar of C++ is undecidable}, Scala, and Rust undecidable).
Unless type features are considered very carefully, they can often create undecidable type checking (Java generics, C++ templates, Scala implicit parameters\footnote{without a maximum search depth} and OCaml modules, make type checking undecidable in those languages).
Haskell may be the most popular statically typed language with decidable type checking (and even then popular GHC compiler flags make type checking undecidable).
Even the Hindley-Milner type checking algorithm that underlies Haskell and ML, has a worst case complexity that is double exponential, which under normal circumstances would be considered intractable.

In practice these theoretical concerns are irrelevant since programmers are not giving the compiler ``worst case'' code.
Even if they did, the worst that can happen is the type checking will hang in the compilation process.
When this happens in a mainstream language, programmers can fix their code, modify or remove macros, or add typing annotations.
Programmers in conventional languages are already entrusted with almost unlimited power over their programming environments.
Programs regularly delete files, read and modify sensitive information, and send emails (some of these are even possible from within the language's macro systems).
Relatively speaking, undecidable type checking is not a programmer's biggest concern.
\todo{a little awk}

Most importantly for the system described in this thesis, users are expected to use the elaboration procedure defined in the next chapter that will bypass the type checking described here.
\todo{than why review?}
% That elaboration procedure is also undecidable, but only for extremely pathological terms.

\section{Related work}

\subsection{Bad logics, ok programming languages?}

Unsound logical systems that work as programming languages go back to at least Church's lambda calculus which was originally intended to be part of a foundation for mathematics\footnote{``There may, indeed, be other applications of the system than its use as a logic.''{[}Church, 1932, p.349, A Set of Postulates for the Foundation of Logic{]}}.\todo{proper citation}
In the 1970s, Per Martin-L{\"o}f proposed a system with \tit{}\todo{cite it?} that was shown logically unsound by Girard (as described in the introduction in \cite{Martin-Lof-1972}).
In the 1980s, Cardelli explored the domain semantics of a system with general recursive dependent functions and \tit{}\cite{cardelli1986polymorphic}.
Independently, Viggo and Stoltenberg-Hansen\cite{PALMGREN1990135} explored the domain semantics of Martin-L{\"o}f's type theory with a fixed point operator.
\todo{Per Martin-L{\"o}f anticipated this work in unpublished lectures and an Abstract.}

The first progress and preservation style proof of type soundness for a language with general recursive dependent functions and \tit{} seem to come from the Trellys Project\cite{sjoberg2012irrelevance}.
At the time their language had several additional features not included in the surface language.
Additionally, the surface language uses a simpler notion of definitional equality resulting in a simpler proof of type soundness.
Later work in the Trellys Project\cite{casinghino2014combining,casinghino2014combiningthesis} used modalities to separate terminating and non-terminating fragments of the language, to allow both general recursion and logically sound reasoning.%, though the annotation burden seems high in retrospect .
In general, the surface language has been deeply informed by the Trellys project\cite{sjoberg2012irrelevance,casinghino2014combining,casinghino2014combiningthesis,sjoberg2015programming,sjoberg2015dependently} and the Zombie language\footnote{https://github.com/sweirich/trellys} it produced.

\todo{type in type as a well known shortcut, videos of Andraj, Conner MB saying it }
\todo{section on \bidir{} dependent type systems, citing http://www.cse.chalmers.se/\textasciitilde nad/publications/altenkirch-et-al-flops2010.pdf https://www.seas.upenn.edu/\textasciitilde sweirich/papers/congruence-extended.pdf posibly https://arxiv.org/pdf/1203.4716.pdf https://drops.dagstuhl.de/opus/volltexte/2021/13919/pdf/LIPIcs-ITP-2021-24.pdf}

\subsection{Implementations}

Several programming language implementations support features of the surface language without a proof of type soundness.
Pebble\cite{10.1007/3-540-13346-1_1} was a very early language with dependent types, though conversion did not associate alpha\todo{if saying alpha need to define it} equivalent types\footnote{according to \cite{Reinhold89typecheckingis}}.
Coquand implemented an early \bidir{} algorithm to type-check a language with \tit{}\cite{COQUAND1996167}.
Cayenne\cite{10.1145/289423.289451} is a Haskell-like language that combines dependent types with \tit{} and non-termination.
$\Pi$$\Sigma$\cite{10.1007/978-3-642-12251-4_5} is a language with \tit{} and several features for a dependently typed core calculus outlined here.
Like here $\Pi$$\Sigma$ advocates seperating terminaition concerns from type soundness concerns, though I am unaware if type soundness was ever established.
Agda supports general recursion and \tit{} with compiler flags.
Idris supports similar ``unsafe'' features.

\subsection{Other Dependent Type Systems}

There are many flavors of dependent type systems that are similar in spirit to the language presented here, but maintain logical soundness at the expense of computation.

The Calculus of Constructions (\ac{CC}, CoC)\cite{10.1016/0890-5401(88)90005-3} is one of the first minimal dependent type systems.
It contains shockingly few rules, but can express a wide variety of constructions via parametric encodings.
The system does not allow \tit{}, instead type\footnote{called \textbf{prop}, for proposition} lives in a larger universe $\star:\Square$, where $\Square$ is not considered a type.
Even though the Calculus of Constructions does not allow \tit{} it is still \textbf{impredicative} in the sense that function types can quantify over $\star$ while still being in $\star$.
For instance, the polymorphic identity $id:(X:\star)\rightarrow X\rightarrow X$ has type $\star$ so the polymorphic identity can be applied to itself, $id\,\left((X:\star)\rightarrow X\rightarrow X\right)\,id$.
From the perspective of the surface language this impredictivity is modest, but still causes issues in the presence of classical logical assumptions. \todo{Cite}
Many of the examples from this chapter are adapted from examples that were first worked out for the Calculus of Constructions.

Several other systems were developed that directly extended or modified the Calculus of Constructions.
The Extended Calculus of Constructions (\ac{ECC})\cite{luo1990extended,luo1994computation}, extends the Calculus of Constructions with a predicative hierarchy of universes and dependent pair types.
The Implicit Calculus of Constructions (\ac{ICC})\cite{10.1007/3-540-45413-6_27,10.1007/978-3-540-78499-9_26} presents an extrinsic typing system\footnote{
  Sometimes called \textbf{Curry-style}, in contrast to intrinsic systems which are sometimes called \textbf{Church-style}.
  }, unlike the Type Assignment System presented in this chapter, the Implicit Calculus of Constructions allows implicit qualification over terms in addition to explicit quantification over terms (also a hierarchy of universes, and a universe of ``sets'').
Other extensions to the Calculus of Constructions that are primarily concerned with data will be surveyed in Chapter 4.

The lambda cube\todo{cite!} is a system for relating 8 interesting typed lambda caluli to each other.
Presuming terms should always depend on terms, there are 3 additional dimensions of dependency: term depending on types, types dependent on types, and types depending on terms.
The simply typed lambda calculus has only term dependency.
System F additionally allows Types to depend on types.
The Calculus of Constructions has all forms of dependency\footnote{Recommended reading Chapter 14 \cite{sorensen2006lectures}}.

Pure Type Systems (\ac{PTS})\footnote{previously called \textbf{Generalized Type Systems}} generalizes the lambda cube to allow any number of type universes with any forms of dependency.
Notably this includes the system with one type universe where \tit{}.
Universe hierarchies can also be embedded in a \ac{PTS}.
The system described in this chapter is almost a \ac{PTS}, except that it contains unrestricted recursion and the method of type annotation is different.
All pure type systems such as System F and the Calculus of Constructions have corresponding terms in the Surface Language, by renaming their type universes into the surface language type universe.

\todo{citations for PTS: (Terlouw, 1989; Berardi, 1988; Barendregt, 1991, 1992; Jutting, McKinna, and Pollack, 1994; McKinna and Pollack, 1993; Pollack, 1994).
According to TAPL}

As previously mentioned Martin L{\"o}f Type Theory (\ac{MTLL})\cite{Martin-Lof-1972} is one of the oldest frameworks for dependent type systems.
MLTT is designed to be open, so that new constructs can be added with the appropriate introduction, elimination, computation, and typing rules.
The base system comes with a predicative hierarchy of universes, and at least dependently typed functions and a propositional equality type.
The system has two flavors characterized by its handling of definitional equality.
If types are only identified by convertibility (as the system described in this chapter) it is called Intentional Type Theory (\ac{ITT}).
If the system allows proofs of equality to associate types, it is called Extensional Type Theory (\ac{ETT}).
Since \ac{MTLL} is open ended, the Calculus of Constructions can be added to it as a subsystem\cite{aspinall2004dependent,hofmann1997extensional}.

\todo{go back to Russle?}
\todo{solving universe constraints?}
\todo{cite the autosubst proof}



% \bidir{}
% [109] Benjamin C. Pierce and David N. Turner. Local type inference. ACM Transactions on Programming Languages and Systems, 22(1):144, January 2000.

% cbn
%  Vilhelm Sjoberg and Aaron Stump. Equality, quasi-implicit products, and large
% eliminations. In ITRS 2010: Proceedings of the 5th workshop on Intersection
% Types and Related Systems, 2010. doi: 10.4204/EPTCS.45.7.


% atosubst