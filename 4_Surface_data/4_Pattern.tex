
\section{Pattern Matching}

Unfortunately, the direct eliminator style is cumbersome for programmers to deal with.
For instance, Figure \ref{fig:data-eliminators} shows how $\mathtt{Vec}$ data can be directly eliminated to extract the first element of a non-empty list in the definition of $\mathtt{head'}$.
The $\mathtt{head'}$ function needs to redirect unreachable vector inputs to a dummy type ($\mathtt{Unit}$) and requires several copies of the same $\mathtt{A}$ variable that are not identified automatically by the eliminator described in the last section.
The usual solution is to extend \case{} elimination with \textbf{pattern matching}.
 
Pattern matching is much more ergonomic than a direct eliminator \case{}.
In Figure \ref{fig:data-eliminators}, the $\mathtt{head}$ and $\mathtt{mapVec}$ functions that are defined though pattern matching is simpler and clearer.
Additionally nested constructor matching is now possible as in the $\mathtt{sub3}$ function.

When pattern matching is extended to dependent types, variables will be assigned their definitions as needed, and unreachable branches can be omitted from code.
For this reason, pattern matching has been considered an ``essential'' feature for dependently typed languages since \cite{coquand1992pattern} and is implemented in most popular systems, such as Agda and the user facing language of Coq.

% This style of case elimination is pervasive in ML style languages and has become popular in more mainstream languages such as Python and Java (double check and perhaps not restrictions)

\begin{figure}
\begin{lstlisting}[basicstyle={\ttfamily\small}]
-- direct eliminator style
head' : (A : *) -> (n : Nat)
  -> Vec A (S n) 
  -> A ;
head' A n v =
  case A, (S n), v <
    A' => n' => _ : Vec A' n' =>
      case n' < _ => *> {
        | (Z  ) => Unit
        | (S _) => A'
      }
  >{
  | _ => _ => (Nil _       ) => tt
  | _ => _ => (Cons _ a _ _) => a
  } ;

-- pattern match style
head : (A : *) -> (n : Nat)
  -> Vec A (S n) 
  -> A ;
head A n v =
  case v < _ => A > {
  | (Cons _ a _ _) => a
  } ;

mapVec : (A : *) -> (n : Nat) -> Vec A n 
  -> (B : *) -> (A -> B)
  -> Vec B n ;
mapVec A n v B f =
  case v 
  < _ : Vec A n => Vec B n >{
  | (Nil A)          => Nil B
  | (Cons A a pn pv) 
    => Cons B (f a) pn (mapVec A pn pv B f)
  };

sub3 : Nat -> Nat ;
sub3 n =
  case n < _ => Nat > {
  | (S (S (S x))) => x
  | _ => 0
  } ;
\end{lstlisting}

\todo[inline]{clean when I get motive inference working}

\todo[inline]{example def by cases}

\caption{Eliminators vs. Pattern Matching}
\label{fig:data-eliminators}
\end{figure}

% Surface data syntax
Figure \ref{fig:surface-data} shows the extensions to the \slang{} for data and pattern matching.
Our \case{} expression matches a list of \scruts{}, allowing us to be very precise about the typing of branches.
Additionally this style allows for syntactic sugar for easy definitions of functions by cases.
The direct eliminator style \case{} of the last section is a special case of pattern matching outlined here.
\todo{Example of why it was needed}

\begin{figure}
\begin{tabular}{lcll}
$m...$ & $\Coloneqq$ & ... & \tabularnewline
 & $|$ & $\case{} \,\overline{n,}\,\left\{ \overline{|\,\overline{pat\Rightarrow}m}\right\} $ & data elim. without motive\tabularnewline
 & $|$ & $\case{} \,\overline{n,}\,\left\langle \overline{x\Rightarrow}M\right\rangle \left\{ \overline{|\,\overline{pat\Rightarrow}m}\right\} $ & data elim. with motive\tabularnewline
\multicolumn{4}{l}{patterns,}\tabularnewline
$pat$ & $\Coloneqq$ & $x$ & match a variable\tabularnewline
 & $|$ & $(d\,\overline{pat})$ & match a constructor\tabularnewline
\end{tabular}

\caption{\SLang{} Data}
\label{fig:surface-data}
\end{figure}

Patterns correspond to a specific form of expression syntax.
When an expression matches a pattern it will capture the relevant subexpressions as variables.
For instance, the expression,
  $\Cons{}\,\Bool{}\,\True{}\,3\,\left(\Cons{}\,\Bool{}\,\False{}\,2\,y'\right)$
  will match the patterns:
\begin{itemize}
\item $\Cons{}\,w\,x\,y\,z$ with bindings $w=\Bool{}$, $x=\True{}$, $y=3$, $z=\Cons{}\,\Bool{}\,\False{}\,2\,y'$
\item $x$ with bindings $x = \Cons{}\,\Bool{}\,\True{}\,3\,\left(\Cons{}\,\Bool{}\,\False{}\,2\,y'\right)$
\item $\Cons{}\,-\,x\,-\,\left(\Cons{}\,-\,y\,-\,-\right)$ with bindings $x = \True{}$, $y = \False{}$
\end{itemize}
When patterns are used in the \case{} construct, the appropriate branch will reduce with the correct bindings in scope.
Therefore the expression 

% $\case{} \,Cons\,\mathbb{B}\,true\,\left(S\left(S\left(S\left(Z\right)\right)\right)\right)\,\left(Cons\,\mathbb{B}\,false\,\left(S\left(S\left(Z\right)\right)\right)\,y'\right)\left\{ Cons\,-\,x\,-\,\left(Cons\,-\,y\,-\,-\right)\Rightarrow x\&y\right\} $
$\case{}\,\Cons{}\,\Bool{}\,\True{}\,3\,\left(\Cons{}\,\Bool{}\,\False{}\,2\,y'\right)
 \left\{ \Cons{}\,-\,x\,-\,\left(\Cons{}\,-\,y\,-\,-\right)\Rightarrow x\&y\right\} $

reduces to \False{}.

The explicit rules for pattern matching are listed in Figure \ref{fig:surface-data-match}, where $\sigma$ will hold a possibly empty set of assignments.

\begin{figure}
\[
\frac{\,}{x\ \mathbf{Match}_{\left\{ x\coloneqq m\right\} }\ m}
\]

\[
\frac{\overline{pat}\ \mathbf{Match}_{\sigma}\ \overline{m}}{d\overline{pat}\ \mathbf{Match}_{\sigma}\ d\overline{m}}
\]

\[
\frac{pat'\ \mathbf{Match}_{\sigma'}\ n\quad\overline{pat}\ \mathbf{Match}_{\sigma}\ \overline{m}}{pat',\overline{pat}\ \mathbf{Match}_{\sigma'\cup\sigma}\ n,\overline{m}}
\]
\[
\frac{\,}{.\,\mathbf{Match}_{\emptyset}\,.}
\]

\caption{\SLang{} Match}
\label{fig:surface-data-match}
\end{figure}

It is now easier for \case{} branches to overlap, which could allow non-deterministic reduction.
There are several plausible ways to handle this, such as requiring each branch to have independent patterns, or requiring patterns have the same behavior when they overlap \cite{10.1007/978-3-642-54833-8_6}.
For the purposes of this thesis, we will use the programmatic convention that the first matching pattern takes precedence.
For example, the following will type check

\[
\case{}\,4\,\left\langle s:\Nat{}\Rightarrow\Bool{}\right\rangle \left\{ |\Suc{}\left(\Suc{}\,-\right)\Rightarrow \True{}\,|\,-\Rightarrow \False{}\right\} 
\]

and it will reduce to \True{}.

% pattern matching is hard
While pattern matching is an extremely practical feature, typing these expressions tends to be messy.
To implement dependently typed pattern matching, a procedure is needed to resolve the equational constraints that arise within each pattern, and to confirm the impossibility of unwritten branches.\todo{ven generate impossible branches}

Since arbitrary computation can be embedded in the arguments of a type constructor\footnote{
  At least in a \fullSp{} theory, such as the one we study here.
}, the equational constraints are undecidable in general.
Any approach to constraint solving will have to be an approximation that performs well enough in practice.
Usually this procedure takes the form of a first order unification. 

%Similarly it is undecidable when a given pattern cannot be inhabited, so coverage checking will also necessarily be a conservative approximation.

% Unfortunately, the unification procedure involves terms outside of the pattern,  hence it is hard to pinpoint the exact point of error to the pattern.
% Worryingly, it is easy to unintentionally validate or contradict principles like Streicher's axiom K, or the Law of the Excluded Middle.

\todo[inline]{talk about or formalize the more subtle inference in the actual system}

\subsection{First Order Unification}

When type checking the branches of a \case{} expression, the patterns are interpreted as expressions under bindings for each variable used in the pattern.
If these equations can be unified, then the branch will type-check under the variable assignments, with the additional typing information.
For instance,
\begin{example}
Type checking by unification

The pattern $\Cons{}\,x\,\left(\Suc{}\,y\right)\,2\,z$ could be checked against the type $\Vect{}\,\Nat{}\,w$.

This implies the typings $x:\star$, $y:\Nat{}$, $\left(S\,y\right):x$, $2:\Nat{}$, $z:\Vect{}\,x\,2,\left(\Cons{}\,x\,\left(\Suc{}\,y\right)\,2\,z\right):\Vect{}\,\Nat{}\,w$.

Which in turn imply the equalities $x=\Nat{}$,$w=3$
\end{example}

This is a simple example, in the worst case we may have equations in the form $m\,n=m'\,n'$ which are hard to solve directly (but may become easy to solve if assignment of $m=\lambda x.x$, and $m'=\lambda-.0$ are discovered).

One advantage of the first order unification approach is that if the algorithm succeeds, it will succeed with a unique, most general solution.
Since assignments are maximal, we are sure that a unified pattern will still be able to match any well typed syntax.

A simplified version of a typical unification procedure is listed in \Fref{surface-data-unification}.
% Several variations are explored in \cite{cockx_devriese_2018}.
Unification is not guaranteed to terminate since it relies on definitional equalities, which are undecidable in the \slang{}.
The unification procedure should also exclude the possibly cyclic assignments that could occur, such as $x=\Suc{}\,x$.\todo{work this into the rules if not too much work}

\begin{figure}
\[
\frac{\,}{U\left(\emptyset,\emptyset\right)
}\rulename{U-emp}
\]

\[
\frac{U\left(E,S\right)\quad m\equiv m'}{U\left(\left\{ m\approx m'\right\} \cup E,S\right)
}\rulename{U-Del}
\]

\[
\frac{
  U\left(E\left[x\coloneqq m\right],S\left[x\coloneqq m\right]\right)
}{
  U\left(\left\{ x\approx m\right\} \cup E,\left\{x\coloneqq m\right\} \cup S \right)
}\rulename{U-var-L}
\]

\[
\frac{
  U\left(E\left[x\coloneqq m\right],S\left[x\coloneqq m\right]\right)
}{
  U\left(\left\{ m\approx x\right\} \cup E, \left\{ x\coloneqq m\right\}  \cup S  \right)
}\rulename{U-var-R}
\]

\[
\frac{
  U\left(\overline{m\approx m'}\cup E,S\right)\quad n\equiv d\overline{m}\quad n'\equiv d\overline{m'}
}{
  U\left(\left\{ n\approx n'\right\} \cup E,S\right)
}\rulename{U-DCon-inj}
\]

\[
\frac{
  U\left(\overline{m\approx m'}\cup E,S\right)\quad N\equiv D\overline{m}\quad N'\equiv D\overline{m'}
}{
  U\left(\left\{ N\approx N'\right\} \cup E,S\right)
}\rulename{U-TCon-inj}
\]
\todo[inline]{sepearte conv rule? better quantifiers for overlining}
\caption{\SLang{} Unification}
\label{fig:surface-data-unification}
\end{figure}
\todo{note the untyped nature, typed varients}
After the branches have type checked we should make sure that they are exhaustive, such that every possible branch will be covered.
Usually this is done by generating a set of patterns that would cover all combinations of constructors and proving that the unlisted branches are unreachable.
In general it is undecidable whether any given pattern is impossible or not, so a practical approximation must be chosen.
Usually a branch is characterized as unreachable if a contradiction is found in the unification procedure.
A programmer will always have the ability to manually include non-obviously unreachable branches and prove their unreachability, or direct those branches to dummy outputs.
Though there is a real risk that the unification procedure gets stuck in ways that are not clear to the programmer, and an understandable error message may be very difficult.

But that set of patterns must still be generated, given the explicit branches the programmer introduced.
There is no clear best way to do this since a more fine division of patterns may allow enough additional definitional information to show unsatisfiability, while a more coarse division of patterns will be more efficient.
Agda uses a tree branching\todo{cite} approach that is efficient, but generates course patterns.
The implementation of the language in this thesis generates patterns by a system of complements, this system seems slightly easier to implement, more uniform, and generates a finer set of patterns then the case trees used in Agda.
However this approach is less performant then Agda in the worse case.

The \bidir{} system can be extended with pattern matching with rules that look like 

\[
\frac{\begin{array}{c}
\Gamma\vdash\overline{n}\overrightarrow{\,:\,}\ \Delta\\
\Gamma,\Delta\vdash M\overleftarrow{\,:\,}\star\\
\forall\:i\,\left(\Gamma\vdash\overline{pat}_{i}:_{E}?\Delta\quad U\left(E,\sigma\right)\quad\sigma\left(\Gamma,|\overline{pat}_{i}|\right)\vdash\sigma m\overleftarrow{\,:\,}\sigma\left(M\left[\Delta\coloneqq\overline{pat}_{i}\right]\right)\right)\\
\Gamma\vdash\overline{\overline{pat}}:\Delta\ \mathbf{complete}
\end{array}}{\begin{array}{c}
\Gamma\vdash \case{} \,\overline{n,}\,\left\langle \Delta_{?}\Rightarrow M\right\rangle \left\{ \overline{|\,\overline{pat\Rightarrow}m}\right\} \\
\overrightarrow{\,:\,}M\left[\Delta_{?}\coloneqq\overline{n}\right]
\end{array}}
\]

\todo{more detail}

\[
\frac{\begin{array}{c}
\Gamma\vdash\overline{n}\overrightarrow{\,:\,}\ \Delta\\
\forall\:i\,\left(\Gamma\vdash\overline{pat}_{i}:_{E}?\Delta\quad U\left(E,\sigma\right)\quad\sigma\left(\Gamma,|\overline{pat}_{i}|\right)\vdash\sigma m\overleftarrow{\,:\,}\sigma\left(M\right)\right)\\
\Gamma\vdash\overline{\overline{pat}}:\Delta\ \mathbf{complete}
\end{array}}{\Gamma\vdash \case{} \,\overline{n,}\,\left\{ \overline{|\,\overline{pat\Rightarrow}m}\right\} \overleftarrow{\,:\,}M}
\]

Where $\Gamma\vdash\overline{pat}:_{E}?\Delta$ is shorthand for a set of equations that allow a list of patterns to type check under $\Delta$, 
  and $\Gamma\vdash\overline{\overline{pat}}:\Delta\ \mathbf{complete}$ is shorthand for the exhaustiveness check. 
\begin{conjecture}
There exists a suitable\footnote{
  Supporting at least subject reduction, type soundness, and regularity.
} extension to the \slang{} \ac{TAS} that supports pattern matching style elimination
\end{conjecture}
\begin{conjecture}
The \bidir{} extension listed here is weakly annotatable with that extension to the \slang{}.
\end{conjecture}
 
These conjectures are not obvious since pattern matching's unification is not necessarily preserved under reduction, or even well typed substitution.
These properties could be recovered by limiting the flexible(assignable) variables of unification to those that appear in the pattern.
Though doing so seems a little arbitrary, and is limiting to the programmer.
For instance, in $\mathtt{mapVec}$ the programmer will need to add the length of the \Vect{} to the pattern match so that $n$ is flexible.
Another way to formalize a \ac{TAS} is to use explicit contextual equalities as in \cite{sjoberg2015dependently}.
 
The prototype implementation goes further than what is outlined here.
For instance, the prototype allows some additional type annotations in the motive and for these annotations to switch the type inference of the \scrut{} into a type-check.
The implementation also has a simple syntax for modules, and even mutually defined data types.
For simplicity these have been excluded from the presentation here.