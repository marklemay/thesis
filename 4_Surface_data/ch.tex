\chapter{Data in the Surface Langugae}
\label{chapter:SurfaceData}
\thispagestyle{myheadings}

\todo{more on parameters /indicies}
\todo{flex vars, could probly make a s.r. system if unification is limited}

User defined data is an important part of a realistic programming
language. Programmers need to be able to define concrete types that
are meaningful for the the problems they are trying to solve.

Dependent data types allow these user defined types, while also unifying
many types that are handled as special cases in most mainstream languages.
For instance, ``primitive'' data types like $\mathtt{Nat}$ and
$\mathtt{Bool}$ are a degenerate forms of dependent data. Dependent
data can represent mathematical predicates like equality or the evenness
of a number. Dependent data can also be used to preserve invariants,
like the length of a list in $\mathtt{Vec}$, or the ``color'' of
a node in a red-black-tree.

The encoding scheme for data presented in Chapter 2 could handle all
of these cases. However, such an encoding is inconvenient in practice.
Since ``ease of use'' is the overriding concern for the system developed
in this thesis, those encoding are an unrealistic way to use data.
% However, the combination of user defined data and dependent types can be subtle.

In this chapter we will show two different, closely related ways to
add data to the surface language and bidirectional system. The first,
a direct eliminator scheme, is meta-theoretically well behaved but
cumbersome. The second is based on pattern matching, and is extremely
useful for programmers, though its meta-theory is much more difficult.
The specific form of pattern matching in this chapter is designed
to allow syntactic sugar of function definition by cases. 

\section{Data}

%What data defs/ constructors
% The langugae defined in this thesus uses data definitions like those found in systems like Agda and Coq. 

A dependent data type is defined by a type constructor indexed by
arguments, and a set of data constructors that tag data and characterize
their arguments. Several familiar data types are defined in Figure
\ref{fig:data-defs}. For example, the data type $\mathtt{Nat}$ is
is defined with the type constructor $\mathtt{Nat}$ (which has no
type arguments), the data constructors $\mathtt{Z}$ which takes no
further information and the data constructor $\mathtt{S}$ which is
formed with the prior number. The data type $\mathtt{Vec}$ has two
type arguments corresponding to the the type contained in the vector
and its length, it has two data constructors that allow building an
empty vector, or to add an element to the front of an existing vector.

Data defined in this style is simple to build and reason about, since
data can only be created from its constructors. Unfortunately the
details of data elimination are a little more involved.

\begin{figure}
\begin{lstlisting}[basicstyle={\ttfamily\small}]
data Void : * {};

data Unit : * {
| tt : Unit
};

data Bool : * {
| True : Bool
| False : Bool
};
 
data Nat : * {
| Z : Nat
| S : Nat -> Nat
};
three : Nat;
three = S (S (S Z)));
-- Syntactic sugar allows 3 = S (S (S Z)))

data Vec : (A : *) -> Nat -> * {
| Nil  : (A : *) -> Vec A Z
| Cons : (A : *) -> A -> (x : Nat)
        -> Vec A x -> Vec A (S x)
};

someBools : Vec Bool 2;
someBools = Cons Bool True 1 (Cons Bool False 0 (Nil Bool));

data Id : (A : *) -> A -> A -> * {
| refl  : (A : *) -> (a : A) -> Id A a a
};

threeEqThree : Id Nat three three;
threeEqThree = refl Nat three;
\end{lstlisting}
% include if notation is used
% -- Syntactic sugar expands list notation,
% -- for example
% -- [True, False]<Bool> =
% -- Cons Bool True 1 (Cons Bool False 1 (Nil Bool))
 \caption{Definitions of Common Data Types}
\label{fig:data-defs}
\end{figure}


\section{Direct Elimination}

How should a program observe data? Since a term of a given data type
can only be created with one of the constructors from its definition,
we can completely handle a data expression if each possible constructor
is accounted for. For instance, $\mathtt{Nat}$ has the two constructors
$\mathtt{Z}$ and $\mathtt{S}$ (which holds the preceding number),
so the expression $\mathsf{case}\,n\,\left\{ |\,Z\Rightarrow Z\,|\,S\,x\Rightarrow x\right\} $
will extract the proceeding number from $n$(or $0$ if $n=0$). In
this light, boolean case elimination corresponds to the if-then-else
expression found in many mainstream languages. 

We will need to extend the syntax of $\mathsf{case}$s to support
dependent type checking. Specifically, we will need to add a \textbf{motive}
annotation that allows the type checker to compute the output type
of the branches if they vary in terms of the input. For instance,
recursively generating a vector of a given length\todo{give explicit example, note the motive}.
We may also want to use some values of the type level argument to
calculate the motive, and type the branches. This will be allowed
with additional bindings in the motive and in each branch\todo{give explicit of data eliminations that uses these annotations}.
In general, motive annotations will be treated like the typing annotations
in Chapter 2, in that the TAS will only allow correct motives in a
well typed term, and that the motive will be definitionally irrelevant.

This version of data can be given by extending the surface language
syntax in Chapter 2, as in Figure \ref{fig:data-defs}. Data Type
constructors and Data Term constructors are treated like functions.
This direct eliminator scheme, is roughly similar to how Coq handles
data in it's core language.
\begin{figure}
\begin{tabular}{lcll}
\multicolumn{4}{l}{list of $O$, separated with $s$}\tabularnewline
$\overline{sO}$,$\overline{Os}$ & $\Coloneqq$ & $.$ & empty list\tabularnewline
 & | & $sO\overline{sO}$ & extend list\tabularnewline
$\Delta,\varTheta$ & $\Coloneqq$ & $\overline{\left(x:M\right)\rightarrow}$ & telescope\tabularnewline
\multicolumn{4}{l}{data type identifier,}\tabularnewline
$D$ &  &  & \tabularnewline
\multicolumn{4}{l}{data constructor identifier,}\tabularnewline
$d$ &  &  & \tabularnewline
\multicolumn{4}{l}{contexts,}\tabularnewline
$\Gamma$ & $\Coloneqq$ & ... & \tabularnewline
 & | & $\Gamma,\mathsf{data}\,D\,:\,\Delta\rightarrow\star\,\left\{ \overline{|\,d\,:\,\varTheta\rightarrow D\overline{m}}\right\} $ & data def extension\tabularnewline
 & | & $\Gamma,\mathsf{data}\,D\,:\,\Delta\rightarrow\star$ & abstract data extension\tabularnewline
$m,n,M,N$ & $\Coloneqq$ & ... & \tabularnewline
 & | & $D$ & type cons.\tabularnewline
 & | & $d$ & data cons.\tabularnewline
 & | & $\mathsf{case}\,\overline{N,}n\,\left\{ \overline{|\overline{x\Rightarrow}(d\,\overline{y})\Rightarrow m}\right\} $ & data elim. without motive\tabularnewline
 & | & $\mathsf{case}\,\overline{N,}n\,\left\langle \overline{x\Rightarrow}\,y:D\,\overline{x}\Rightarrow M\right\rangle \left\{ \overline{|\overline{x\Rightarrow}(d\,\overline{y})\Rightarrow m}\right\} $ & data elim. with motive\tabularnewline
\multicolumn{4}{l}{values,}\tabularnewline
$v$ & $\Coloneqq$ & ... & \tabularnewline
 & | & $D\,\overline{v}$ & \tabularnewline
 & | & $d\,\overline{v}$ & \tabularnewline
\end{tabular}

\caption{Surface Language (Direct Eliminator) Data}
\label{fig:surface-data-min}
\end{figure}

\begin{figure}
\begin{tabular}{llllll}
 & syntax & written & when & for example & is written\tabularnewline
leading separator & $sO\overline{sO}$ & $O\overline{sO}$ & clear from context & $,1,2,3$ & $1,2,3$\tabularnewline
trailing separator & $\overline{sO}$ & $\overline{sO}s$ & clarifies intent & $\left(x\rightarrow y\rightarrow z\right)Id\,x\,y\,z$ & $x\rightarrow y\rightarrow z\rightarrow Id\,x\,y\,z$\tabularnewline
non dependent telescope binder & $\left(x:M\right)\rightarrow$ & $M\rightarrow$ & $x$is not intended to bind  & $\left(x:Nat\right)\rightarrow\left(y:IsEven\,x\right)\rightarrow Nat$ & $\left(x:Nat\right)\rightarrow IsEven\,x\rightarrow Nat$\tabularnewline
repeated application & $m\,n_{0}\,n_{1}\,...$ & $m\,\overline{n}$ & $\overline{n}=n_{0}\,n_{1}\,...$ &  & \tabularnewline
\end{tabular}

\todo[inline]{review if there are more abbreviations around?}

\caption{Surface Language Abbreviations}
\label{fig:surface-pre-syntax-data-abrev-1}
\end{figure}

\todo[inline]{motive should not need to insist on the type info of the binder? grey
out?Grey out things that are surface syntax but not needed for theory?}

The case eliminator first takes the explicit type arguments, followed
by a \textbf{scrutinee}\footnote{also called a \textbf{discriminee}}
of correct type. Then optionally a motive that characterizes the output
type of each branch with all the type arguments and scrutinee abstracted
and in scope. For instance, this case expression checks if a vector
$x$ is empty,

\[
x:Vec\,\mathbb{B}\,1\vdash\mathsf{case}\,\mathbb{B},1,x\,\left\langle y\Rightarrow z\Rightarrow s:Vec\,y\,z\Rightarrow\mathbb{B}\right\rangle \left\{ |y\Rightarrow z\Rightarrow Nil\,-\Rightarrow True\,|\,y\Rightarrow z\Rightarrow Cons\,----\Rightarrow False\right\} 
\]

We include a little more syntax then is strictly necessary, since
the $\mathbb{B},1,$ list could be inferred and the $y\Rightarrow z\Rightarrow$
binders are not needed in the branch. This slightly verbose case eliminator
syntax is designed to be forward compatible with the pattern matching
system defined in the rest of this chapter. 

Additionally we define telescopes, which generalize zero or more typed
bindings\todo{Cite De Bruijn for telescopes}. This allows a much
cleaner definition of data then is otherwise possible. Also we define
syntactic lists that allow zero or more pieces of syntax. Expressions
in a list can be used to generalize dependent pairs, and can be type
checked against a telescope. For instance, the list $\mathtt{Nat},2,2,refl\,\mathtt{Nat}\,2$
type checks against $\left(X:\star\right)\rightarrow\left(y:X\right)\rightarrow\left(z:X\right)\rightarrow\left(-:Id\ X\,y\,z\right)$.
This becomes helpful in several situations, but especially when we
need work with the listed arguments of the data type constructor.
We will allow several syntactic puns, such as treating telescopes
as prefixes for function types. For instance, if $\Delta=\left(y:\mathtt{Nat}\right)\rightarrow\left(z:\mathtt{Nat}\right)\rightarrow\left(-:Id\ \mathtt{Nat}\,y\,z\right)$
then writing $f:\Delta\rightarrow\mathtt{Nat}$ will be short hand
for $f:\left(y:\mathtt{Nat}\right)\rightarrow\left(z:\mathtt{Nat}\right)\rightarrow Id\ \mathtt{Nat}\,y\,z\rightarrow\mathtt{Nat}$.
\todo{move this down to the typing section?}

In the presence of general recursion case elimination is powerful.
Well-founded recursion can be used to make structurally inductive
computations that can be interpreted as proofs.\todo{say with rep example}.

Adding data allows for two additional sources of bad behavior. Incomplete
matches, and nontermination from non-strictly positive data. 

\subsubsection{Incomplete Eliminations}

Consider the match 

\[
x:\mathbb{N}\vdash\mathsf{case}\,x\,\left\langle s:\mathbb{N}\Rightarrow\mathbb{B}\right\rangle \left\{ |S-\Rightarrow True\right\} 
\]

This match will ``get stuck'' if $0$ is substituted for $x$. Recall
that the key theorem of the surface language is type soundness, ``well
typed terms don't get stuck''. Since verifying every constructor
has a branch is relatively easy, the surface language TAS will require
every constructor to be matched in order to type check type check
with direct elimination. This is in contrast to most programming languages,
which do allow incomplete patterns, though usually a warning is given,
and a runtime error is raised if the scrutinee cannot be matched.

% Since this is a "well behaved" failure

This thesis already has a system for handling warnings and runtime
errors through the cast language. When we get to the cast language,
we will allow non-exhaustive data to be reported as a warning and
that will allow ``unmatched'' errors to be observed at runtime.

For similar reasons, in the direct eliminator scheme, we will insist
that each constructor is matched at most once, so there is no ambiguity
for how an case eliminated when using direct eliminations.

\subsubsection{(non-)Strict Positivity}

A more subtle concern is posed by data definitions that are not strictly
positive. Consider the following definition, \todo{TODO think this can be simplified}

\begin{lstlisting}[basicstyle={\ttfamily\small}]
data Bad : * {
| C : (Bad -> Bad) -> Bad
};

selfApply : Bad -> Bad;
selfApply = \ b =>
  case b {
    | C f => f b
  };

loop : Bad;
loop = selfApply (C selfApply)
\end{lstlisting}

The $\mathtt{C}$ constructor in the definitions of $\mathtt{Bad}$
has a self reference in a negative position, $(\mathtt{Bad}\rightarrow\underline{\mathtt{Bad}})\rightarrow\mathtt{Bad}$. 

Non-strictly positive data definitions can cause non-termination,
independent of the two other sources of non-termination already considered
(general recursion and type-in-type). Dependent type systems usually
require a strictness check on data definitions to avoid this possibility.
However, this would disallow some useful constructions like higher
order abstract syntax. Since non-termination is already allowed in
the surface TAS, we will not restrict the surface language to strictly
positive data.

\todo{who cam up with this first? Martin Lof?}

% co-inductive uses of data

\subsection{Type assignment System}

Before the typing rules for data can be considered, first some meta
rules must be presented that will allow the simultaneous type-checking
of lists and telescopes. These rules are listed in \ref{fig:surface-data-meta-ty},
and are standard. Telescopes are $\mathbf{ok}$ when they extend the
context in an $\mathbf{ok}$ way. Lists of expressions can be said
to have the type of the telescope if every expression in the list
types successively.

\begin{figure}
\[
\frac{\Gamma\,\mathbf{ok}}{\Gamma\vdash.\,\mathbf{ok}}\operatorname{\mathbf{ok}-Tel-empty}
\]

\[
\frac{\Gamma\vdash M:\star\quad\Gamma,x:M\vdash\Delta\,\mathbf{ok}}{\Gamma\vdash\left(x:M\right)\rightarrow\Delta\,\mathbf{ok}}\operatorname{\mathbf{ok}-Tel-ext}
\]

\[
\frac{\Gamma\,\mathbf{ok}}{\Gamma\vdash,:.}\operatorname{ty-ls-empty}
\]

\[
\frac{\Gamma,x:M\vdash\Delta\quad\Gamma\vdash m:M\quad\Gamma\vdash\overline{n,}\left[x\coloneqq m\right]:\Delta\left[x\coloneqq m\right]}{\Gamma\vdash m\overline{,n}\,:\,\left(x:M\right)\rightarrow\Delta}\operatorname{ty-ls-ext}
\]

\caption{Meta rules}
\label{fig:surface-data-meta-ty}
\end{figure}

Data definitions can be added to contexts if all of their constituents
are well typed and \textbf{ok}. The rules are listed in Figure \ref{fig:surface-data-ok}.
The $\operatorname{\mathbf{ok}-abs-data}$ rule allows data to be
considered abstractly if it is formed with a plausible telescope.
$\operatorname{\mathbf{ok}-data}$ checks a full data definition with
an abstract reference to a data definition in context, which allows
recursive data definitions such as $\mathtt{Nat}$ which needs $\mathtt{Nat}$
to be in scope to define the $\mathtt{S}$ constructor. This thesis
does not formalize a syntax that adds data to context, though a very
simple module system has been implemented in the prototype. It is
taken for granted that any well formed data in context is fine. This
presentation of data definitions largely follows \cite{sjoberg2012irrelevance}. 

\begin{figure}
\[
\frac{\Gamma\vdash\Delta\,\mathbf{ok}}{\Gamma\vdash\mathsf{data}\,D\,\Delta\,\mathbf{ok}}\operatorname{\mathbf{ok}-abs-data}
\]

\[
\frac{\Gamma\vdash\mathsf{data}\,D\,\Delta\,\mathbf{ok}}{\Gamma,\mathsf{data}\,D\,\Delta\,\mathbf{ok}}\operatorname{\mathbf{ok}-data-ext}
\]
\[
\frac{\Gamma\vdash\mathsf{data}\,D\,\Delta\,\mathbf{ok}\quad\forall d.\Gamma,\mathsf{data}\,D\,\Delta\vdash\varTheta_{d}\,\mathbf{ok}\quad\forall d.\:\Gamma,\mathsf{data}\,D\,\Delta,\varTheta_{d}\vdash\overline{m}_{d}:\Delta}{\Gamma\vdash\mathsf{data}\,D\,:\,\Delta\left\{ \overline{|\,d\,:\,\varTheta_{d}\rightarrow D\overline{m}_{d}}\right\} \,\mathbf{ok}}\operatorname{\mathbf{ok}-data}
\]

\[
\frac{\Gamma\vdash\mathsf{data}\,D\,:\,\Delta\left\{ \overline{|\,d\,:\,\varTheta\rightarrow D\overline{m}}\right\} \,\mathbf{ok}}{\Gamma,\mathsf{data}\,D\,:\,\Delta\left\{ \overline{|\,d\,:\,\varTheta\rightarrow D\overline{m}}\right\} \,\mathbf{ok}}\operatorname{\mathbf{ok}-data-ext}
\]

\caption{Surface Language Data ok}
\label{fig:surface-data-ok}
\end{figure}

The type assignment system with direct elimination must be extended
with the rules in \ref{fig:surface-data-ty}. These rules make use
of several convenient shorthands: $\mathsf{data}\,D\,\Delta\in\Gamma$
and $d\,:\,\varTheta\rightarrow D\overline{m}\in\Gamma$ extract the
type constructor definitions and data constructor definitions from
the context respectively. $\operatorname{ty-TCon}$ and $\operatorname{ty-Con}$
allow type and data constructors to be used as functions of appropriate
type. The $\operatorname{ty-}\mathsf{case}<>$ rule types a case expression
by ensuring that the correct data definition for $D$ is in context,
the scrutinee $n$ has the correct type, the motive $M$ is well formed
under the type arguments and the scrutinee, % The motive requires checking in the case of empty data
finally every data constructor is verified to have a corresponding
branch. $\operatorname{ty-}\mathsf{case}$ allows for the same typing
logic, but does not require the motive be annotated in syntax. In
both rules we allow telescopes to rename their variables with the
shorthand $\overline{x}:\Delta$.

\begin{figure}
\[
\frac{\Gamma\,\mathbf{ok}\quad\mathsf{data}\,D\,\Delta\in\Gamma}{\Gamma\vdash D\,:\,\Delta\rightarrow\star}\operatorname{ty-TCon}
\]

\[
\frac{\Gamma\,\mathbf{ok}\quad d\,:\,\varTheta\rightarrow D\overline{m}\in\Gamma}{\Gamma\vdash d\,:\,\varTheta\rightarrow D\overline{m}}\operatorname{ty-Con}
\]

\[
\frac{\begin{array}{c}
\mathsf{data}\,D\,\Delta\left\{ ...\right\} \in\Gamma\\
\Gamma\vdash n:D\overline{N}\\
\Gamma,\overline{x}:\Delta,z:D\,\overline{x}\vdash M:\star\\
\forall\:d\,:\,\varTheta\rightarrow D\overline{o}\in\Gamma.\quad\Gamma,\overline{y}_{d}:\varTheta\vdash m_{d}\left[\overline{x}\coloneqq\overline{o}\left[\varTheta\coloneqq\overline{y}_{d}\right]\right]:M\left[\overline{x}\coloneqq\overline{o}\left[\varTheta\coloneqq\overline{y}_{d}\right],z\coloneqq d\,\overline{y}_{d}\right]\\
\mathrm{No\ duplicate\ branches}
\end{array}}{\begin{array}{c}
\Gamma\vdash\mathsf{case}\,\overline{N,}n\,\left\langle \overline{x\Rightarrow}z:D\,\overline{x}\Rightarrow M\right\rangle \left\{ \overline{|\,\overline{x\Rightarrow}\,d\overline{y}_{d}\,\Rightarrow m_{d}}\right\} \\
:M\left[\overline{x}\coloneqq\overline{N},z\coloneqq n\right]
\end{array}}\operatorname{ty-}\mathsf{case}<>
\]

\[
\frac{\begin{array}{c}
\mathsf{data}\,D\,\Delta\left\{ ...\right\} \in\Gamma\\
\Gamma\vdash n:D\overline{N}\\
\Gamma,\overline{x}:\Delta,z:D\,\overline{x}\vdash M:\star\\
\forall\:d\,:\,\varTheta\rightarrow D\overline{o}\in\Gamma.\quad\Gamma,\overline{y}_{d}:\varTheta\vdash m_{d}\left[\overline{x}\coloneqq\overline{o}\left[\varTheta\coloneqq\overline{y}_{d}\right]\right]:M\left[\overline{x}\coloneqq\overline{o}\left[\varTheta\coloneqq\overline{y}_{d}\right],z\coloneqq d\,\overline{y}_{d}\right]
\end{array}}{\begin{array}{c}
\Gamma\vdash\mathsf{case}\,\overline{N,}n\,\left\{ \overline{|\,\overline{x\Rightarrow}\,d\overline{y}_{d}\,\Rightarrow m_{d}}\right\} \\
:M\left[\overline{x}\coloneqq\overline{N},z\coloneqq n\right]
\end{array}}\operatorname{ty-}\mathsf{case}
\]

\caption{Surface Language Data Typing}
\label{fig:surface-data-ty}
\end{figure}

\todo[inline]{suspect this also hinges on regularity, which should be addressed
more directly}

Extensions to the parallel reduction rules are listed in Figure \ref{fig:surface-data-red}.
They follow the scheme of parallel reductions laid out in Chapter
2. The $\textrm{\ensuremath{\Rrightarrow}-\ensuremath{\mathsf{case}}-red}$
rule\footnote{Also called $\iota$, or Iota reduction}\todo{mention beta in CH2}
reduces a case expression by choosing the appropriate branch. The
$\textrm{\ensuremath{\Rrightarrow}-\ensuremath{\mathsf{case}}<>-red}$
rule removes the motive annotation, much like the annotation rule
in Chapter 2. The rules $\textrm{\ensuremath{\Rrightarrow}-\ensuremath{\mathsf{case}}<>}$,
$\textrm{\ensuremath{\Rrightarrow}-}D$, and $\textrm{\ensuremath{\Rrightarrow}-}d$
keep the $\Rrightarrow$ relation reflexive. The reduction relation
is be generalized to lists in the expected way.

\begin{figure}
\[
\frac{\begin{array}{c}
\overline{N}\Rrightarrow\overline{N'}\quad\overline{m}\Rrightarrow\overline{m'}\\
\exists\overline{x\Rightarrow}(d\,\overline{y}_{d})\Rightarrow m_{d}\in\left\{ \overline{|\,\overline{x\Rightarrow}(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} \\
m_{d}\Rrightarrow m_{d}'
\end{array}}{\mathsf{case}\,\overline{N,}\,d\overline{m}\,\left\{ \overline{|\,\overline{x\Rightarrow}(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} \Rrightarrow m_{d}\left[\overline{x}\coloneqq\overline{N'},\overline{y}_{d}\coloneqq\overline{m'}\right]}\,\textrm{\ensuremath{\Rrightarrow}-\ensuremath{\mathsf{case}}-red}
\]

\[
\frac{\begin{array}{c}
\overline{N}\Rrightarrow\overline{N'}\quad m\Rrightarrow m'\\
\forall\overline{x\Rightarrow}(d\,\overline{y}_{d})\Rightarrow m_{d}\in\left\{ \overline{|\,\overline{\Rightarrow x}\Rightarrow(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} .\:m_{d}\Rrightarrow m_{d}'
\end{array}}{\mathsf{case}\,\overline{N,}\,m\,\left\langle ...\right\rangle \left\{ \overline{|\,\overline{\Rightarrow x}\Rightarrow(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} \Rrightarrow\mathsf{case}\,\overline{N',}\,m'\left\{ \overline{|\,\overline{\Rightarrow x}\Rightarrow(d'\,\overline{y}_{d'})\Rightarrow m_{d'}'}\right\} }\,\textrm{\ensuremath{\Rrightarrow}-\ensuremath{\mathsf{case}}<>-red}
\]

\[
\frac{\begin{array}{c}
\overline{N}\Rrightarrow\overline{N'}\quad m\Rrightarrow m'\\
M\Rrightarrow M'\\
\forall\overline{x\Rightarrow}(d'\,\overline{y}_{d'})\Rightarrow m_{d'}\in\left\{ \overline{|\,\overline{\Rightarrow x}\Rightarrow(d\,\overline{y}_{d})\Rightarrow m_{d}}\right\} .\:m_{d'}\Rrightarrow m'_{d'}
\end{array}}{\begin{array}{c}
\mathsf{case}\,\overline{N,}\,m\,\left\langle \overline{x\Rightarrow}z:D\,\overline{x}\Rightarrow M\right\rangle \left\{ \overline{|\,\overline{\Rightarrow x}\Rightarrow(d\,\overline{y}_{d})\Rightarrow m_{d}}\right\} \Rrightarrow\\
\mathsf{case}\,\overline{N,}\,m'\,\left\langle \overline{x\Rightarrow}z:D\,\overline{x}\Rightarrow M'\right\rangle \left\{ \overline{|\,\overline{\Rightarrow x}\Rightarrow(d\,\overline{y}_{d})\Rightarrow m'_{d}}\right\} 
\end{array}}\,\textrm{\ensuremath{\Rrightarrow}-\ensuremath{\mathsf{case}}<>}
\]

\[
\frac{\,}{D\Rrightarrow D}\,\textrm{\ensuremath{\Rrightarrow}-}D
\]
\[
\frac{\,}{d\Rrightarrow d}\,\textrm{\ensuremath{\Rrightarrow}-}d
\]

\caption{Surface Language Data Reduction}
\label{fig:surface-data-red}
\end{figure}

We are now in a position to select a sub relation of $\Rrightarrow$
reductions that will be used to characterize call-by-value evaluation.
This relation could be used used to prove type safety, and is close
to the reduction used in the implementation. The rules are listed
in Figure \ref{fig:surface-data-cbv}.\todo[inline]{extend cbv over lists}

\begin{figure}
\[
\frac{\,}{\mathsf{case}\,\overline{N,}\,n\,\left\langle ...\right\rangle \left\{ \overline{|\,\overline{\Rightarrow x}\Rightarrow(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} \rightsquigarrow\mathsf{case}\,\overline{N,}\,n\left\{ \overline{|\,\overline{\Rightarrow x}\Rightarrow(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} }\textrm{\ensuremath{\rightsquigarrow}-\ensuremath{\mathsf{case}}<>}
\]

\[
\frac{\exists\overline{x\Rightarrow}(d\,\overline{y}_{d})\Rightarrow m_{d}\in\left\{ \overline{|\,\overline{x\Rightarrow}(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} }{\mathsf{case}\,\overline{V,}\,d\overline{v}\,\left\{ \overline{|\,\overline{x\Rightarrow}(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} \rightsquigarrow m_{d}\left[\overline{x}\coloneqq\overline{V},\overline{y}_{d}\coloneqq\overline{v}\right]}\,\textrm{\ensuremath{\rightsquigarrow}-\ensuremath{\mathsf{case}}-red}
\]

\[
\frac{\overline{N}\rightsquigarrow\overline{N'}}{\mathsf{case}\,\overline{N,}\,n\,\left\{ \overline{|\,\overline{x\Rightarrow}(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} \rightsquigarrow\mathsf{case}\,\overline{N',}\,n\,\left\{ \overline{|\,\overline{x\Rightarrow}(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} }\,
\]

\[
\frac{n\rightsquigarrow n'}{\mathsf{case}\,\overline{V,}\,n\,\left\{ \overline{|\,\overline{x\Rightarrow}(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} \rightsquigarrow\mathsf{case}\,\overline{V,}\,n'\,\left\{ \overline{|\,\overline{x\Rightarrow}(d'\,\overline{y}_{d'})\Rightarrow m_{d'}}\right\} }\,
\]

\caption{Surface Language Data CBV}
\label{fig:surface-data-cbv}
\end{figure}

\todo[inline]{extend step over lists}

Finally we characterize what it means for a context to be empty in
the presence of data in Figure \ref{fig:surface-data-empty}.

\begin{figure}
\[
\frac{\ }{\lozenge\,\mathbf{Empty}}\operatorname{Empty-ctx}
\]

\[
\frac{\Gamma\,\mathbf{Empty}\quad\Gamma\vdash\mathsf{data}\,D\,:\,\Delta\left\{ \overline{|\,d\,:\,\varTheta_{d}\rightarrow D\overline{m}_{d}}\right\} \,\mathbf{ok}}{\Gamma,\mathsf{data}\,D\,:\,\Delta\left\{ \overline{|\,d\,:\,\varTheta_{d}\rightarrow D\overline{m}_{d}}\right\} \,\mathbf{Empty}}\operatorname{Empty-ctx}
\]

\caption{Surface Language Empty}
\label{fig:surface-data-empty}
\end{figure}

While a system with a similar presentation has proven type soundness
in \cite{sjoberg2012irrelevance}\todo{switch to vilhelms thesis?}
, we will not prove the type soundness of the system here. For clarity
we will list the important properties as conjectures.
\begin{conjecture}
The surface language extended with data and elimination preserves
types over reduction.
\end{conjecture}

% ...
\begin{conjecture}
The surface language extended with data and elimination has progress
if $\Gamma\,\mathbf{Empty}$, \textup{$\Gamma\vdash m:M$}, then $m$
is a value, or $m\rightsquigarrow m'$ .
\end{conjecture}

% ...
\begin{conjecture}
The surface language extended with data and elimination is type sound.
\end{conjecture}


\subsection{Bidirectional Type Checking}

A bidirectional type checking procedure exists for the type assignment
rules listed above. An outline of these rules is in Figure \ref{fig:surface-data-empty}.
As noted in \cite{10.1145/3450952}, the bidirectional rules around
data are open to some interpretation. The dependent case simplifies
these questions since only a few rules are sensable.

The type of data constructors and type constructors can always be
inferred. If the motive does not depend on the scrutinee or type arguments,
it can be used to check against the type of the branches. An unmotivated
$\mathsf{case}$ will be type checked. A $\mathsf{case}$ with a motive
will have its type inferred.

\begin{figure}
\[
\frac{\mathsf{data}\,D\,\Delta\in\Gamma}{\Gamma\vdash D\overrightarrow{\,:\,}\Delta\rightarrow*}\operatorname{\overrightarrow{ty}-TCon}
\]

\[
\frac{d\,:\,\varTheta\rightarrow D\overline{m}\in\Gamma}{\Gamma\vdash d\overrightarrow{\,:\,}\varTheta\rightarrow D\overline{m}}\operatorname{\overrightarrow{ty}-Con}
\]

\[
\frac{\begin{array}{c}
\mathsf{data}\,D\,\Delta\left\{ ...\right\} \in\Gamma\\
\Gamma\vdash\overline{N}\overleftarrow{\,:\,}\Delta\quad\Gamma\vdash n\overleftarrow{\,:\,}D\overline{N}\\
\Gamma,\overline{x}:\Delta,z:D\,\overline{x}\vdash M\overleftarrow{\,:\,}\star\\
\forall\:d\,:\,\varTheta\rightarrow D\overline{o}\in\Gamma.\quad\Gamma,\overline{y}_{d}:\varTheta\vdash m_{d}\left[\overline{x}\coloneqq\overline{o}\right]\overleftarrow{\,:\,}M\left[\overline{x}\coloneqq\overline{o},z\coloneqq d\,\overline{y}_{d}\right]
\end{array}}{\begin{array}{c}
\Gamma\vdash\mathsf{case}\,\overline{,N},n\,\left\langle \overline{x\Rightarrow}z:D\,\overline{x}\Rightarrow M\right\rangle \left\{ \overline{|\,\overline{x\Rightarrow}(d\,\overline{y}_{d})\Rightarrow m_{d}}\right\} \\
\overrightarrow{\,:\,}M\left[\overline{x}\coloneqq\overline{N},z\coloneqq n\right]
\end{array}}\operatorname{\overrightarrow{ty}-}\mathsf{case}<>
\]

\[
\frac{\begin{array}{c}
\mathsf{data}\,D\,\Delta\left\{ ...\right\} \in\Gamma\\
\Gamma\vdash\overline{N}\overleftarrow{\,:\,}\Delta\quad\Gamma\vdash n\overrightarrow{\,:\,}D\overline{N}\\
\Gamma\vdash M\overleftarrow{\,:\,}\star\\
\forall\:d\,:\,\varTheta\rightarrow D\overline{o}\in\Gamma.\quad\Gamma,\overline{y}_{d}:\varTheta\vdash m_{d}\left[\overline{x}\coloneqq\overline{o}\right]\overleftarrow{\,:\,}M
\end{array}}{\Gamma\vdash\mathsf{case}\,\overline{N,}n\,\left\{ \overline{|\overline{x\Rightarrow}\,(d\,\overline{y}_{d})\Rightarrow m_{d}}\right\} \overleftarrow{\,:\,}M}\operatorname{\overleftarrow{ty}-}\mathsf{case}<>
\]

\todo[inline]{reparam o in $\left[\overline{x}\coloneqq\overline{o}\right]$ also}

\caption{Surface Language Bidirectional type checking }
\label{fig:surface-data-bi-ty}
\end{figure}

We can confidently conjecture that the desired bidirectional properties
hold.
\begin{conjecture}
\textbf{T}he data extension to the bidirectional surface language
is type sound.
\end{conjecture}

% ...
\begin{conjecture}
\textbf{T}he data extension to the bidirectional surface language
is weakly annotatable from the data extension of the surface language.\todo{symbolically}
\end{conjecture}

This is a minimal (and somewhat crude) accounting of bidirectional
data. It is possible to imagine syntactic sugar that doesn't require
the $\overline{N,}$ and $\overline{x\Rightarrow}\,$ the in case
expression of the $\operatorname{\overleftarrow{ty}-}\mathsf{case}<>$
rule. In the dependent rule $\operatorname{\overrightarrow{ty}-}\mathsf{case}<>$
it is also possible to imagine some type constructor arguments being
inferred. These features and more will be subsumed by the dependent
pattern matching of the next section, though this will complicate
the meta-theory.

\section{Pattern Matching}

Unfortunately, the direct eliminator style is cumbersome for programmers
to deal with. For instance, Figure \ref{fig:data-eliminators} shows
how $\mathtt{Vec}$ data can be directly eliminated to extract the
first element of a non-empty list in the definition of $\mathtt{head'}$.
The $\mathtt{head'}$ function needs to redirect unreachable vector
inputs to a dummy type ($\mathtt{Unit}$) and requires several copies
of the same $\mathtt{A}$ variable that are not identified automatically
by the eliminator described in the last section. The usual solution
is to extend case elimination with \textbf{Pattern matching.}

Pattern matching is much more ergonomic than a direct eliminator $\mathsf{case}$.
In Figure \ref{fig:data-eliminators}, the $\mathtt{head}$ defined
though pattern matching is simpler and clearer. Nested constructor
matching is now possible. When pattern matching is extended to dependent
types variables will be assigned their definitions as needed, and
unreachable branches can be omitted from code. For this reason, pattern
matching has been considered an ``essential'' feature for dependently
typed languages since \cite{coquand1992pattern} and is implemented
implemented in most popular systems, such as Agda and the user facing
language of Coq.

% This style of case elimination is pervasive in ML style languages and has become popular in more mainstream languages such as Python and Java (double check and perhaps not restrictions)

\begin{figure}
\begin{lstlisting}[basicstyle={\ttfamily\small}]
 -- direct eliminator style
 head' : (A : *) -> (n : Nat) ->
   Vec A (S n) ->
   A ;
 head' A n v =
   case A, (S n), v <
     A' => n' => _ : Vec A' n' =>
       case n' < _ => *> {
         | (Z  ) => Unit
         | (S _) => A'
       }
   >{
   | _ => (Z)   => (Nil _       ) => tt
   | _ => (S _) => (Cons _ a _ _) => a
   } ;

  -- pattern match style
 head : (A : *) -> (n : Nat) ->
   Vec A (S n) ->
   A ;
 head A n v =
   case v < _ => A > {
   | (Cons _ a _ _) => a
   } ;
\end{lstlisting}

\todo[inline]{match the single eliminator syntax}

\todo[inline]{clean when I get motive inference working}

\todo[inline]{example def by cases}

\caption{Eliminators vs. Pattern Matching}
\label{fig:data-eliminators}
\end{figure}

% Surface data syntax
Figure \ref{fig:surface-data} shows the extensions to the surface
language for data and pattern matching. Our case expression match
a list of scrutinees, allowing us to be very precise about the typing
of branches. Additionally this style allows for syntactic sugar for
easy definitions of functions by cases. The syntax of the direct eliminator
style $\mathsf{case}$s of the last section was designed to be a special
case of pattern matching. \todo{Example of why it was needed}
\begin{figure}
\begin{tabular}{lcll}
$m...$ & $\Coloneqq$ & ... & \tabularnewline
 & | & $\mathsf{case}\,\overline{n,}\,\left\{ \overline{|\,\overline{pat\Rightarrow}m}\right\} $ & data elim. without motive\tabularnewline
 & | & $\mathsf{case}\,\overline{n,}\,\left\langle \overline{x\Rightarrow}M\right\rangle \left\{ \overline{|\,\overline{pat\Rightarrow}m}\right\} $ & data elim. with motive\tabularnewline
\multicolumn{4}{l}{patterns,}\tabularnewline
$pat$ & $\Coloneqq$ & $x$ & match a variable\tabularnewline
 & | & $(d\,\overline{pat})$ & match a constructor\tabularnewline
\end{tabular}

\caption{Surface Language Data}
\label{fig:surface-data}
\end{figure}

Patterns correspond to a specific form of expression syntax. When
an expression matches a pattern it will capture the relevant subexpressions
as variables. For instance, the expression. 

$Cons\,\mathbb{B}\,true\,\left(S\left(S\left(S\left(Z\right)\right)\right)\right)\,\left(Cons\,\mathbb{B}\,false\,\left(S\left(S\left(Z\right)\right)\right)\,y'\right)$

will match the patterns
\begin{itemize}
\item $Cons\,w\,x\,y\,z$ with bindings $w=\mathbb{B}$, $x=true$, $y=3$,
$z=Cons\,\mathbb{B}\,false\,\left(S\left(S\left(Z\right)\right)\right)\,y'$
\item $x$ with bindings $x=Cons\,\mathbb{B}\,true\,\left(S\left(S\left(S\left(Z\right)\right)\right)\right)\,\left(Cons\,\mathbb{B}\,false\,\left(S\left(S\left(Z\right)\right)\right)\,y'\right)$ 
\item $Cons\,-\,x\,-\,\left(Cons\,-\,y\,-\,-\right)$ with bindings $x=true$,
$y=false$
\end{itemize}
When patterns are used in the case construct, the appropriate branch
will reduce with the correct bindings in scope. Therefore the expression 

$\mathsf{case}\,Cons\,\mathbb{B}\,true\,\left(S\left(S\left(S\left(Z\right)\right)\right)\right)\,\left(Cons\,\mathbb{B}\,false\,\left(S\left(S\left(Z\right)\right)\right)\,y'\right)\left\{ Cons\,-\,x\,-\,\left(Cons\,-\,y\,-\,-\right)\Rightarrow x\&y\right\} $
reduces to $false$.

The explicit rules for pattern matching are listed in Figure \ref{fig:surface-data-match},
where $\sigma$ will hold a possibly empty set of assignments.

\begin{figure}
\[
\frac{\,}{x\ \mathbf{Match}_{\left\{ x\coloneqq m\right\} }\ m}
\]

\[
\frac{\overline{pat}\ \mathbf{Match}_{\sigma}\ \overline{m}}{d\overline{pat}\ \mathbf{Match}_{\sigma}\ d\overline{m}}
\]

\[
\frac{pat'\ \mathbf{Match}_{\sigma'}\ n\quad\overline{pat}\ \mathbf{Match}_{\sigma}\ \overline{m}}{pat',\overline{pat}\ \mathbf{Match}_{\sigma'\cup\sigma}\ n,\overline{m}}
\]
\[
\frac{\,}{.\,\mathbf{Match}_{\emptyset}\,.}
\]

\caption{Surface Language Match}
\label{fig:surface-data-match}
\end{figure}

It is now easier for case branches to overlap, which could allow nondeterministic
reduction. There are several plausible ways to handle this, such as
requiring each branch to have independent patterns, or requiring patterns
have the same behavior when they overlap \cite{10.1007/978-3-642-54833-8_6}.
For the purposes of this thesis, we will use the programatic convention
that the first matching pattern takes precedence. For example, we
will be able to type check

\[
\mathsf{case}\,4\,\left\langle s:\mathbb{N}\Rightarrow\mathbb{B}\right\rangle \left\{ |S\left(S\,-\right)\Rightarrow True\,|\,-\Rightarrow False\right\} 
\]

and it will reduce to $True$.

% pattern matching is hard
While pattern matching is an extremely practical feature, typing these
expressions tends to be messy. To implement dependently typed pattern
matching, a procedure is needed to resolve the equational constraints
that arise within each pattern, and to confirm the impossibility of
unwritten branches.

Since arbitrary computation can be embedded in the arguments of a
type constructor\footnote{At least in a full spectrum theory, such as the one we study here.},
the equational constraints are undecidable in general. Any approach
to constraint solving will have to be an approximation that performs
well enough in practice. Usually this procedure usually takes the
form of a first order unification. 

%Similarly it is undecidable when a given pattern cannot be inhabited, so coverage checking will also necessarily be a conservative approximation.

% Unfortunately, the unification procedure involves terms outside of the pattern,  hence it is hard to pinpoint the exact point of error to the pattern.
% Worryingly, it is easy to unintentionally validate or contradict principles like Streicher's axiom K, or the Law of the Excluded Middle.

\todo[inline]{talk about or formalize the more subtle inference in the actual system}

\subsection{First Order Unification}

When type checking the branches of the a case expression, the patterns
are interpreted as expressions under bindings for each variable used
in the pattern. If these equations can be unified, then the brach
will type-check under the variable assignments, with the additional
typing information. For instance,
\begin{example}
Type checking by unification

the pattern $Cons\,x\,\left(S\,y\right)\,2\,z$

could be checked against the type $Vec\,Nat\,w$

this implies the typings $x:*,y:Nat,\left(S\,y\right):x,2:Nat,z:Vec\,x\,2,\left(Cons\,x\,\left(S\,y\right)\,2\,z\right):Vec\,Nat\,w$

which in turn imply the equalities $x=Nat,w=3$
\end{example}

This is a very simple example, in the worst case we may have equations
in the form $m\,n=m'\,n'$ which are hard to solve directly (but may
become easy to solve if assignment of $m=\lambda x.x$, and $m'=\lambda-.0$
are discovered).

One advantage of the first order unification approach is that if the
algorithm succeeds, it will succeed with a unique, most general solution.
Since assignments are maximal, we are sure that a unified pattern
will still be able to match any well typed syntax.

A simplified version of a typical unification procedure is listed
in Figure \ref{fig:surface-data-unification}. Several variations
are explored in \cite{cockx_devriese_2018}. Unification is not guaranteed
to terminate since it relies on definitional equalities, which are
undecidable in the surface language. The unification procedure does
not exclude the possibly cyclic assignments that could occur, such
as $x=S\,x$\todo{as a threat to soundness this should be corrected?}. 

\begin{figure}
\[
\frac{\,}{U\left(\emptyset,\emptyset\right)}
\]

\[
\frac{U\left(E,a\right)\quad m\equiv m'}{U\left(\left\{ m\sim m'\right\} \cup E,a\right)}
\]

\[
\frac{U\left(E\left[x\coloneqq m\right],a\left[x\coloneqq m\right]\right)}{U\left(\left\{ x\sim m\right\} \cup E,\left\{ a,x\coloneqq m\right\} \right)}
\]

\[
\frac{U\left(E\left[x\coloneqq m\right],a\left[x\coloneqq m\right]\right)}{U\left(\left\{ m\sim x\right\} \cup E,a\cup\left\{ x\coloneqq m\right\} \right)}
\]

\[
\frac{U\left(\overline{m}\sim\overline{m'}\cup E,a\right)\quad n\equiv d\overline{m}\quad n'\equiv d\overline{m'}}{U\left(\left\{ n\sim n'\right\} \cup E,a\right)}
\]

\[
\frac{U\left(\overline{m}\sim\overline{m'}\cup E,a\right)\quad N\equiv D\overline{m}\quad N'\equiv D\overline{m'}}{U\left(\left\{ N\sim N'\right\} \cup E,a\right)}
\]

\caption{Surface Language Unification}
\label{fig:surface-data-unification}
\end{figure}

After the branches have type checked we should makes sure that they
are exhaustive, such that every possible branch will be covered. Usually
the is done by generating a set of patterns that would cover all combinations
of constructors and proving that the unlisted branches are unreachable.
In general it is undecidable wether any given pattern is impossible
or not, so a practical approximation must be chosen. Usually a branch
is characterized as unreachable if a contradiction is found in the
unification procedure. At least programmers have the ability to manually
include non-obviously unreachable branches and prove their unreachability,
(or direct those branches to dummy outputs). Though there is a real
risk that the unification procedure gets stuck in ways that are not
clear to the programmer, and a clean error message may be very difficult.

But that set of patterns must still be generated, given the explicit
branches the programmer introduced. There is no clear best way to
do this since a more fine devision of patterns may allow enough additional
definitional information to show unsatisfiability, while a more coarse
devision of patterns will be more efficient. Agda uses a tree branching
approach, that is efficient, but generates course patterns. The implementation
of the language in this thesis generates patterns by a system of complements,
this system seams slightly easier to implement, more uniform, and
generates a much finer set of patterns then the case trees used in
Agda. However this approach is exponentially less performant then
Agda in the worse case.

The bidirectional system can be extended with pattern matching with
rules that look like 

\[
\frac{\begin{array}{c}
\Gamma\vdash\overline{n}\overrightarrow{\,:\,}\ \Delta\\
\Gamma,\Delta\vdash M\overleftarrow{\,:\,}\star\\
\forall\:i\,\left(\Gamma\vdash\overline{pat}_{i}:_{E}?\Delta\quad U\left(E,\sigma\right)\quad\sigma\left(\Gamma,|\overline{pat}_{i}|\right)\vdash\sigma m\overleftarrow{\,:\,}\sigma\left(M\left[\Delta\coloneqq\overline{pat}_{i}\right]\right)\right)\\
\Gamma\vdash\overline{\overline{pat}}:\Delta\ \mathbf{complete}
\end{array}}{\begin{array}{c}
\Gamma\vdash\mathsf{case}\,\overline{n,}\,\left\langle \Delta_{?}\Rightarrow M\right\rangle \left\{ \overline{|\,\overline{pat\Rightarrow}m}\right\} \\
\overrightarrow{\,:\,}M\left[\Delta_{?}\coloneqq\overline{n}\right]
\end{array}}
\]

\todo{more detail}

\[
\frac{\begin{array}{c}
\Gamma\vdash\overline{n}\overrightarrow{\,:\,}\ \Delta\\
\forall\:i\,\left(\Gamma\vdash\overline{pat}_{i}:_{E}?\Delta\quad U\left(E,\sigma\right)\quad\sigma\left(\Gamma,|\overline{pat}_{i}|\right)\vdash\sigma m\overleftarrow{\,:\,}\sigma\left(M\right)\right)\\
\Gamma\vdash\overline{\overline{pat}}:\Delta\ \mathbf{complete}
\end{array}}{\Gamma\vdash\mathsf{case}\,\overline{n,}\,\left\{ \overline{|\,\overline{pat\Rightarrow}m}\right\} \overleftarrow{\,:\,}M}
\]

where $\Gamma\vdash\overline{pat}:_{E}?\Delta$ is shorthand for a
set of equations that allow a list of patterns to type check under
$\Delta$. and $\Gamma\vdash\overline{\overline{pat}}:\Delta\ \mathbf{complete}$
is shorthand for the exhaustiveness check. 
\begin{conjecture}
Their exists a suitable\footnote{supporting at least subject reduction, type soundness, and regularity}
extension to the surface language TAS that supports patten matching
style elimination
\end{conjecture}

This conjecture is not obvious since pattern matching is not consistent
under reduction, or even well typed substitution. Probably the best
way to work in that direction is to use explicit contextual equalities
as in \cite{sjoberg2012irrelevance}.
\begin{conjecture}
The bidirectional extension listed here is weakly annotatable with
that extension to the surface language.
\end{conjecture}

Additionally, it makes sense to allow some additional type annotations
in the motive and for these annotations to switch the the type inference
of the scrutinee into a type-check. The implementation includes this
along with a simple syntax for modules, and even mutually defined
data types. For simplicity these have been excluded from the formal
presentation.

\section{Discussion}

\todo{ECHO VIEW from the left to explore this more}

\todo{Inductive families? don't seem to make sense in this formulation}

Pattern matching seems simple, but is a surprisingly subtle.

Even without dependent types, pattern matching is a strange programming
construct. How important is it that patterns correspond exactly to
a subset expression syntax? What about capture annotations or side
conditions? Restricting patterns to constructors and variable means
that it is hard to encapsulate functionality, a problem noticed as
early as\cite{10.1145/41625.41653} \todo{review}. This has lead
to making pattern behavior override-able in Scala via Extractor Objects.
An extension in GHC allows some computations to happen within a pattern
match via the $ViewPatterns$ extension \todo{lots of prior work https://gitlab.haskell.org/ghc/ghc/-/wikis/view-patterns}.
It seems unreasonable to extend patterns to arbitrary computation
(though this is allowed in the Curry language\footnote{https://curry.pages.ps.informatik.uni-kiel.de/curry-lang.org/}
as a syntax for its logical programming features). 

In the presence of full-spectrum dependent types, the perspective
dramatically shifts. Any terminating typing procedure will necessarily
exclude some type-able patterns and be unable to exclude some unreachable
branches. Even though only data values are considered, dependent patterns
are already attacking a much more difficult problem then in the non-dependent
case. It may make sense to extend the notion of pattern matching to
include other useful but difficult features. One such interesting
feature was the $\mathsf{with}$ syntax of \cite{mcbride_mckinna_2004}.

\todo{discuss stuck state of unification explicitly, x = f a vs. f a = g
b, and how it for instance makes it so you can't prove transitivity
of ID fa gb, ID gb hc -> ID fa hc. also calls into quesiton preservation
entirely. }

Epigram, Agda and Idris make pattern matching more powerful using
$\mathsf{with}$ syntax that allows further pattern based branching
by attaching a computation to a branch. This is justified as syntactic
sugar that corresponds to helper functions that can be appropriately
elaborated and type-checked. The language described in this thesis
does not use the $\mathsf{with}$ side condition since nested case
expressions carry the same computational behavior, and the elaboration
to the cast language will allow possibly questionable typing anyway.

More aggressive choices should be explored beyond the $\mathsf{with}$
construct. In principle it seems that dependent case expressions could
be extended with relevant proof search, arbitrary computation or some
amount of constraint solving, without being any theoretically worse
than usual first order unification. 

\todo[inline]{Discus how stratified type systems like ATS handle things (additional
equational information)}

% There are other questions that How should overlapping branches be handled? (think this got covered)

The details of pattern matching change the logical character of the
system\cite{cockx_devriese_2018}. Since non-termination is allowed
in the language described here, the logical issues that arise from
pattern are less of a concern then the immediate logical unsoundness
that was discussed in chapter 2. However it is worth noting that pattern
matching as described here validates axiom k and thus appears unsuitable
for Hott or CTT developments.

This chapter has glossed over the definitional behavior of $\mathsf{case}$s,
since we plan to sidestep definitional issues entirely with the cast
language. It is worth noting that their are several ways to set up
the definitional reductions. Agda style case trees may result in unpredictable
definitional equalities (in so far as definitional behavior is ever
predictable) \cite{10.1007/978-3-642-54833-8_6} \todo{review}. \cite{10.1007/978-3-642-54833-8_6}
advocates for a more conservative approach that makes function definitions
by cases definitional (but shifts the difficulties to overlapping
branches and does not allow the ``first match'' behavior programmers
are used to). Another extreme would be to only allow reductions when
the scrutinee is a value, similar to the work in \cite{sjoberg2012irrelevance}\todo{confirm}.
Alternatively a partial reduction is possible, such that branches
are eliminated as they are found unreachable and substitutions made
as they are available. This last approach is experimentally implemented
for the language defined here. However it is unclear how partial reduction
could be handled in the meta-theory.

Patten matching complicates the simple story from Chapter 2, where
the bidirectional system made the TAS system checkable by only adjusting
annotations. We have only conjectured the existence of a suitable
TAS system for pattern matching. If the definitional equality that
feeds the TAS is generated by a system of reductions, any of the reduction
strategies listed above will generate a different TAS with subtly
different characteristics. For instance, insisting on a call-by-value
case reduction will leave many equivalent computations unassociated.
If the TAS system uses partial reductions it will need to inspect
the constructors of the scrutinee in order to preserve typing when
reduction eliminates branches. Agda style reductions need to extend
syntax under reduction to account for side conditions. 

% For this reason it is rare to see a fully formailized account of pattern matching.

Ideally the typing rule for pattern matching case expression in the
TAS should not use the notion of unification at all. Instead the rule
should characterize the behavior that is required directly and formally\footnote{\cite{coquand1992pattern} has a good informal description}.
An ideal rule might look like

\[
\frac{\begin{array}{cl}
\Gamma\vdash\overline{n}:\Delta' & (scrutinees\ type\ check)\\
\Gamma,\overline{x}:\Delta'\vdash M:\star & (motive\ exists\ and\ is\ well\ formed)\\
\forall i.\:? & (every\ branch\ is\ well\ typed\ over\ all\ possible\ instantiations)\\
? & (all\ scrutinees\ are\ handled)
\end{array}}{\Gamma\vdash\mathsf{case}\,\overline{n,}\,\left\{ \overline{|\,\overline{pat\Rightarrow}_{i}m_{i}}\right\} :M\left[\overline{x}\coloneqq\overline{n}\right]}\,...
\]

% Where the last condition is optional if you're willing to modify type soundness to allow pattern match errors (again, they are no worse then the non-termination already allowed, and better behaved).

\section{Related work}

\subsection{Dependent Systems with Data}

Many systems that target data only formalize a representative collection
of data types, expecting the reader to be able to generalize the scheme.
This data usually covers Nats (for recursive types) and dependent
pairs (for dependent types) % and unit to end a chain of dependent pairs.
For example, Martin Lof's\todo{accent} original paper treated data
this way\todo{confirm, cite}, and is still a common approach to data
(for instance in \cite{jia2010dependent}).

% Martin Lof generalized the notion of data to W types of well founded trees  and this still serves as a theoretical justification for data.

Unified Type Theory (UTT)\cite{luo1990extended,luo1994computation}
is an extension to ECC that specifies a scheme to define strictly
positive data types by way of a logical framework defined in MLTT.
This scheme generates primitive recursors for schematized data, and
does not inherently support pattern matching.

The Calculus of Inductive Constructions (CiC) is an extension to the
calculus of constructions that includes a system of first class data
definitions. It evolved form Calculus of Constructions with Inductive
Definitions (CCID) which was first presented in, \cite{10.1007/BFb0037116}
but the most complete up to date formulation is maintained as part
of the Coq manual \footnote{https://coq.github.io/doc/v8.9/refman/language/cic.html}.
A bidirectional account of CIC is given in \cite{lennonbertrand:LIPIcs.ITP.2021.24},
though it uses a different style of bidirectionally then discussed
here to maintain compatibility with the existing Coq system.

\todo[inline]{CTT, higher inductive types, quotient types}

\subsection{Dependent Pattern matching}

\todo[inline]{Clean up this section}

The scheme for dependent pattern matching was first presented by Thierry
Coquand in \cite{coquand1992pattern}.

Mcbride and Mckinna extended the power and theory of dependent pattern
matching with several additional constructs such as $\mathsf{with}$
in\cite{mcbride_mckinna_2004}.

Ulf Norell greatly simplified the presentation of pattern matching
in his thesis \cite{norell2007towards}.

\todo[inline]{A tutorial implementation of dynamic pattern unification Adam Gundry
and Conor McBride (2012) http://adam.gundry.co.uk/pub/pattern-unify/
(this links give you the choice to read a more detailed chapter of
Adam Gundry's thesis instead)}

The subtleties of dependently pattern matching are explored in \cite{cockx_devriese_2018},
which has many informative examples, some of which were motivated
by longstanding bugs in Agda.

\todo[inline]{https://research.chalmers.se/en/publication/519011 ?}

\todo[inline]{https://sozeau.gitlabpages.inria.fr/www/research/publications/Equations:\_A\_Dependent\_Pattern-Matching\_Compiler.pdf
?}

\todo[inline]{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.99.1405\&rep=rep1\&type=pdf
?}


\todo[inline]{barras's thesis data}

