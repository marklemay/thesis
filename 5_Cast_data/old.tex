
\section{OLD JUNK}

\todo[inline]{Substantail changes will be made made to the formulaitons bellow}


\todo[inline]{Example back to pattern matching?}


\begin{figure}

term reductions
\[
\frac{p\rightsquigarrow p'}{!_{p}\rightsquigarrow!_{p'}}
\]

\todo[inline]{could remove more then just assertions}

\[
\frac{\,}{\left\{ \star\sim_{k,o,\ell}\star\right\} \rightsquigarrow\star}
\]

\[
\frac{\,}{\left\{ \left(x:A\right)\rightarrow B\sim_{k,o,\ell}\left(x:A'\right)\rightarrow B'\right\} \rightsquigarrow\left(x:\left\{ A\sim_{k,o.arg,\ell}A'\right\} \right)\rightarrow\left\{ B\sim_{k,o.bod\left[x\right],\ell}B'\right\} }
\]

\[
\frac{\,}{\left\{ \mathsf{fun}\,f\,x\Rightarrow b\sim_{k,o,\ell}\mathsf{fun}\,f\,x\Rightarrow b'\right\} \rightsquigarrow\mathsf{fun}\,f\,x\Rightarrow\left\{ b\sim_{k,o.app\left[x\right],\ell}b'\right\} }
\]

\[
\frac{\,}{\left\{ d\overline{a}\sim_{k,o,\ell}d\overline{a'}\right\} \rightsquigarrow d\overline{\left\{ a_{i}\sim_{k,o.DCon[i],\ell}a'_{i}\right\} }}
\]

\[
\frac{\,}{\left\{ D\overline{a}\sim_{k,o,\ell}D\overline{a'}\right\} \rightsquigarrow D\overline{\left\{ a_{i}\sim_{k,o.TCon[i],\ell}a'_{i}\right\} }}
\]

\todo[inline]{double check}

\[
\frac{\overline{a}\ \mathbf{Match}\ \overline{patc}_{i}}{\mathsf{case}\,\overline{a,}\,\left\{ \overline{|\,\overline{patc\Rightarrow}b_{i}}\overline{|\,\overline{patc'\Rightarrow}!_{\ell}}\right\} \rightsquigarrow b_{i}\left[patc_{i}\coloneqq\overline{a}\right]}
\]

\caption{Summery of Cast Language Reductions}
\label{fig:cast-data-red}
\end{figure}

This extension to the syntax induces many more reduction rules. We
include a summery of selected reduction rules in \ref{fig:cast-data-red}.
We do not show the value restrictions to avoid clutter\footnote{there are also multiple ways to lay them out. For instance we could
evaluate paths left to right or right to left.}. 


\begin{figure}
\todo[inline]{swap, pattern on the left?}

\todo[inline]{record substitutions}

\[
\frac{\,}{a\ \mathbf{Match}\ x}
\]

\[
\frac{\overline{a}\ \mathbf{Match}\ \overline{patc}}{d\,\overline{a}\ \mathbf{Match}\ \left(d\,\overline{patc}\right)::x_{p}}
\]

\[
\frac{\overline{a}\ \mathbf{Match}\ \overline{patc}}{\left(d\,\overline{a}\right)::kcast\ \mathbf{Match}\ \left(d\,\overline{patc}\right)::x_{p}}
\]

\[
\frac{\overline{a}\ \mathbf{Match}\ \overline{patc}}{\left(d\,\overline{a}\right)::kcast\ \mathbf{Match}\ \left(d\,\overline{patc}\right)::x_{p}}
\]

\[
\frac{\,}{.\ \mathbf{Match}\ .}
\]

\[
\frac{b\ \mathbf{Match}\ patc'\quad\overline{a}\ \mathbf{Match}\ \overline{patc}}{b\overline{a}\ \mathbf{Match}\ patc'\overline{patc}}
\]


\caption{Cast Language Matching}
\label{fig:cast-data-match}
\end{figure}

\todo[inline]{double check paths are fully applied when needed}





The Cast language extension defined in this chapter is fairly complex.
Though all the meta-theory of this section is plausible, we have not
fully formalized it, and there is a potential that some subtle errors
exist. To be as clear as possible about the uncertainty around the
meta-theory proposed in this chapter, I will list what would normally
be considered theorems and lemmas as conjectures. \todo{weird place to make this note. add it to the front or back matter?}



We now conjecture the core lemmas that could be used to prove cast
soundness
\begin{conjecture}
substitution of cast terms preserves cast

equivalently the following rule is admissible

\end{conjecture}


% ...
\begin{conjecture}
substitution of cast terms preserves path endpoints

equivalently the following rule is admissible

\end{conjecture}

% ...

Finally we will conjecture the cast soundness.
\begin{conjecture}
The cast system preserves types and path endpoints over normalization
\end{conjecture}

% ...
\begin{conjecture}
a well typed path in an empty context is a value, takes a step, or
produces blame
\end{conjecture}

% ...
\begin{conjecture}
A well typed term in an empty context is a value, takes a step, or
produces blame
\end{conjecture}


\section{Elaborating Eliminations}



% elaboration unification
To make the overall system behave as expected we do not want to expose
users to equality patterns, or force them to manually do the path
bookkeeping. To work around this we extend a standard unification
algorithm to cast patterns with instrumentation to remember paths
that were required for the solution. Then if pattern matching is satisfiable,
compile additional casts into the branch based on its assignments.
Unlisted patterns can be checked to confirm they are unsatisfiable.
If the pattern is unsatisfiable then elaboration can use the proof
of unsatisfiability to construct explicit blame. If an unlisted pattern
cannot be proven ``unreachable'' then we could warn the user, and
like most functional programming languages, blame the incomplete match
if that pattern ever occurs.

\subsection{Preliminaries}

The surface language needs to be enriched with additional location
metadata at each position where the two bidirectional typing modalities
would cause a check in the surface language.

\begin{tabular}{lcll}
$m...$ & $\Coloneqq$ & ... & \tabularnewline
 & | & $\mathsf{case}\,\overline{n_{\ell},}\,\left\{ \overline{|\,\overline{pat\Rightarrow}m_{\ell'}}\right\} $ & data elim. without motive\tabularnewline
 & | & $\mathsf{case}\,\overline{n_{\ell},}\,\left\langle \overline{x\Rightarrow}M_{\ell'}\right\rangle \left\{ \overline{|\,\overline{pat\Rightarrow}m_{\ell''}}\right\} $ & data elim. with motive\tabularnewline
\end{tabular}

The implementation allows additional annotations along the motive,
while this works within the bidirectional framework. The syntax is
not presented here since the theory is already quite complicated.\todo{move note somewhere else}

\subsection{Elaboration}

The biggest extension to the elaboration procedure in Chapter 3 is
the path relevant unification and the insertion of casts to simulate
surface language pattern matching. The unification and casting processes
both work without $k$ assumptions in scope, simplifying the possible
terms that may appear.


\begin{figure}
\[
\frac{\,}{U\left(\emptyset,\emptyset\right)}
\]

\[
\frac{U\left(E,u\right)\quad a\equiv a'}{U\left(\left\{ p:a\thickapprox a'\right\} \cup E,u\right)}
\]

\[
\frac{U\left(E\left[x\coloneqq a\right],u\left[x\coloneqq a\right]\right)}{U\left(\left\{ p:x\thickapprox a\right\} \cup E,u\cup\left\{ p:x\thickapprox a\right\} \right)}
\]

\todo[inline]{actually a little incorrect, needs to use conq to concat the paths}

\[
\frac{U\left(E\left[x\coloneqq a\right],u\left[x\coloneqq a\right]\right)}{U\left(\left\{ p:a\thickapprox x\right\} \cup E,u\cup\left\{ p^{-1}:x\thickapprox a\right\} \right)}
\]

\[
\frac{U\left(\left\{ p:a\thickapprox a'\right\} \cup E,u\right)\quad a\equiv d\overline{b}\quad a'\equiv d\overline{b'}}{U\left(\left\{ Con_{i}p:b_{i}\thickapprox b'_{i}\right\} _{i}\cup E,u\right)}
\]

\todo[inline]{fully applied}

\[
\frac{U\left(\left\{ p:a\thickapprox a'\right\} \cup E,u\right)\quad a\equiv D\overline{b}\quad a'\equiv D\overline{b'}}{U\left(\left\{ TCon_{i}p:b_{i}\thickapprox b'_{i}\right\} _{i}\cup E,u\right)}
\]

\todo[inline]{fully applied}


\todo[inline]{break cycle, make sure x is assignable}

\todo[inline]{double check constraint order}

\todo[inline]{correct vars in 4a}

\caption{Surface Language Unification}
\label{fig:surface-data-unification}
\end{figure}


The elaboration procedure uses the extended unification procedure
to determine the implied type and assignment of each variable. In
the match body casts are made so that variables behave as if they
have the types and assignments consistent with the surface language.
The original casting mechanism is still active, so it is possible
that after all the casting types still don't line up. In this case
primitive casts are still made at their given location.

\todo[inline]{add explicit rules for elaboration?}

The elaboration algorithm is extremely careful to only add casts,
this means erasure is preserved and evaluation will be consistent
with the surface language.

Further the remaining properties from Chapter 3 probably still hold
\begin{conjecture}
Every term well typed in the bidirectional surface language elaborates 
\end{conjecture}

% ..
\begin{conjecture}
Blame never points to something that checked in the bidirectional
system 
\end{conjecture}


\section{Discussion and Future Work}


\subsection{Types invariance along paths}

It turns out that the system defined in Chapter 3 had the advantage
of only dealing with equalities in the type universe. Extending to
equalities over arbitrary type has vastly increased the complexity
of the system. To make the system work paths are untyped, which seems
inelegant. There is nothing currently preventing blame across type.
For instance,

$\left\{ 1\sim_{k,o,\ell}false\right\} $ will generate blame $1\neq false$.
While blame of $Nat\neq Bool$ will certainly result in a better error
message. Several attempts were made to encode the type into the type
assumption, but the resulting systems quickly became too complicated
to work with. Some vestigial typing constraints are still in the system
(such as on the explicit blame) to encourage this cleaner blame.

\subsection{Elaboration is non-deterministic with regard to blame}

Consider the case

\begin{lstlisting}[basicstyle={\ttfamily\small}]
case x <_:Id Nat 2 2 => S 2> {
| refl _ a => s a
}
\end{lstlisting}

that can elaborate to

\begin{lstlisting}[basicstyle={\ttfamily\small}]
case x <_:Id Nat 2 2 => S 2> {
| (refl A a)::p => (s (a::TCon0(p)) :: Cong uncastL(TCon1(p)))
}
\end{lstlisting}

where $p:Id\,A\,a\,a\thickapprox Id\,Nat\,2\,2$, where $TCon_{1}p$
selects the first position $p:Id\,A\,\underline{a}\,a\thickapprox Id\,Nat\,\underline{2}\,2$.
But this could also have elaborated to 

\begin{lstlisting}[basicstyle={\ttfamily\small}]
case x <_:Id Nat 2 2 => S 2> {
| (refl A a)::p => (s (a::TCon0(p)) :: Cong uncastL(TCon2(p)))
}
\end{lstlisting}

relying on $p:Id\,A\,a\,\underline{a}\thickapprox Id\,Nat\,2\,\underline{2}$.
This can make a difference if the scrutinee is 

$refl\ Nat\,2::Id\,Nat\,3\,2::Id\,Nat\,2\,2$

in one case blame will be triggered, in the other it will not. In
this case it is possible to mix the blame from both positions, though
this does not seem to extend in general since the consequences of
inequality are undecidable in general and we intend to allow running
programs if they can maintain their intended types.

\subsection{Extending to Call-by-Value}

As in Chapter 3, the system presented here does the minimal amount
of checking to maintain type safety. This can lead to unexpected results,
for instance consider the surface term 

\begin{lstlisting}[basicstyle={\ttfamily\small}]
case (refl Nat 7 :: Id Nat 2 2) <_ => Nat> {
| refl _ a => a
}
\end{lstlisting}

This will elaborate into 

\begin{lstlisting}[basicstyle={\ttfamily\small}]
case (refl Nat 7 :: Id Nat 2 2) <_ => Nat> {
| (refl A a)::p => a::TCon0(p)
}
\end{lstlisting}

which will evaluate to $7::\mathtt{Nat}$ without generating blame.
And indeed we only ever asserted that the result was of type $\mathtt{Nat}$.

In the implementation, some of this behavior is avoided by requiring
type arguments in a cast be run call-by-value. This restriction will
blame $7\neq2$ before the cast is even evaluated.\todo{expand}

\subsection{Efficiency}

The system defined here is brutally inefficient. 

In theory the system has an arbitrary slow down. As in Chapter 3,
a cast that relies on non-terminating code can itself cause additional
non-termination as paths are resolved.

As written there are many redundant computations, and trying every
combination of assumptions is very inefficient. Currently the implementation
is quite slow, though there are several ways to speed things up. Caching
redundant computation would help. Having a smarter embedding of $k$
assignments would remove redundant work directly. To some extent $Cong$
and $Assert$ can be made multi-arity to allow fewer jumps. But most
helpful of all would be simplifying away unneeded casts. More advanced
options include using proof search to find casts that will never cause
an error.

\todo[inline]{paremetricity}

\todo[inline]{relation to fun-ext}

\todo[inline]{warnings}

\subsection{Relation to UIP}

Pattern matching as outlined in the last Chapter (which follows from
\cite{coquand1992pattern}) implies the \textbf{uniqueness of identity
proofs} (UIP)\footnote{Also called \textbf{axiom k}}. UIP states
that every proof of identity is equal to refl (and thus unique), and
is not provable in many type theories. In univalent type theories
UIP is directly contradicted by the ``non-trivial'' equalities,
required to equate isomorphisms and Id. UIP is derivable in the surface
language by following pattern match 

\begin{lstlisting}[basicstyle={\ttfamily\small}]
case x <pr : Id A a a => Id (Id A a a) pr (refl A a) > {
| refl A a => refl (Id A a a) (refl A a)
}
\end{lstlisting}

This type checks since unification will assign $pr\coloneqq refl\,A\,a$
and under that assumption $refl\ (Id\ A\ a\ a)\ (refl\ A\ a):Id\ (Id\ A\ a\ a)\ (refl\ A\ a)\ (refl\ A\ a)$.
Like univalent type theories, the cast language has its own nontrivial
equalities, so it might seem that the cast language would also contradict
UIP . But it is perfectly compatible, and will elaborate. One interpretation
is that though there are multiple ``proofs'' of identity, we don't
care which one is used. \todo{interpretation + take aways?}


\section{Related work}

This work was previously presented as an extended abstract at the
TyDE workshop\todo[inline]{cite}, the version there reflected a less
plausible meta-theory based on earlier implementation experiments.



